{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Métodos Basados en Densidad - Ejercicios"],"metadata":{"id":"f4PXOybTVtSt"}},{"cell_type":"markdown","metadata":{"id":"CyuXhfmSVjlA"},"source":["---\n","Este cuaderno contiene ejercicios prácticos para consolidar los conceptos del Módulo 4.\n"]},{"cell_type":"markdown","metadata":{"id":"SCxP8NfPVjlD"},"source":["## Configuración Inicial\n","\n","Ejecuta esta celda antes de comenzar los ejercicios."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F4FJYuGUVjlG"},"outputs":[],"source":["# Instalación de HDBSCAN\n","!pip install hdbscan -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-g329zYKVjlI"},"outputs":[],"source":["# Bibliotecas necesarias\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Scikit-learn\n","from sklearn.cluster import DBSCAN, OPTICS, KMeans\n","from sklearn.datasets import make_blobs, make_moons, make_circles\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import NearestNeighbors\n","from sklearn.metrics import silhouette_score, adjusted_rand_score\n","from sklearn.metrics import confusion_matrix\n","\n","# HDBSCAN\n","import hdbscan\n","\n","# Configuración de visualización\n","plt.style.use('seaborn-v0_8-whitegrid')\n","plt.rcParams['figure.figsize'] = (12, 6)\n","plt.rcParams['font.size'] = 11\n","\n","# Reproducibilidad\n","RANDOM_STATE = 42\n","np.random.seed(RANDOM_STATE)\n","\n","print(\"Configuración completada.\")"]},{"cell_type":"markdown","metadata":{"id":"JbGOZv44VjlJ"},"source":["---\n","\n","## Ejercicio 1: Comprensión de los Conceptos de DBSCAN\n","\n","### Contexto\n","\n","Para comprender DBSCAN es fundamental entender los conceptos de epsilon-vecindad y la clasificación de puntos en núcleo, borde y ruido.\n","\n","### Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pgf088MnVjlK"},"outputs":[],"source":["# Dataset pequeño para análisis manual\n","X_ej1 = np.array([\n","    [1.0, 1.0],   # P0\n","    [1.3, 1.2],   # P1\n","    [0.9, 1.4],   # P2\n","    [1.2, 0.8],   # P3\n","    [1.5, 1.1],   # P4\n","    [4.0, 4.0],   # P5\n","    [4.2, 4.3],   # P6\n","    [4.1, 3.8],   # P7\n","    [2.5, 2.5],   # P8 - punto intermedio\n","    [7.0, 1.0]    # P9 - outlier\n","])\n","\n","# Visualización\n","plt.figure(figsize=(10, 8))\n","plt.scatter(X_ej1[:, 0], X_ej1[:, 1], c='steelblue', s=150, edgecolors='w', linewidths=2)\n","for i, (x, y) in enumerate(X_ej1):\n","    plt.annotate(f'P{i}', (x + 0.15, y + 0.15), fontsize=12, fontweight='bold')\n","plt.xlabel('Característica 1')\n","plt.ylabel('Característica 2')\n","plt.title('Dataset para Ejercicio 1')\n","plt.grid(True, alpha=0.3)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"WLd_Ie_yVjlL"},"source":["### Tarea 1.1: Cálculo de Vecindades\n","\n","Dado eps=0.6 y min_samples=3, calcule la epsilon-vecindad de cada punto y determine cuántos vecinos tiene cada uno."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jWmwT2c_VjlM"},"outputs":[],"source":["# Parámetros\n","eps = 0.6\n","min_samples = 3\n","\n","# TODO: Calcular las vecindades usando NearestNeighbors\n","# Use radius_neighbors con el radio eps\n","\n","# Su código aquí\n","nn = None  # Reemplazar\n","vecindades = None  # Reemplazar\n","\n","# Mostrar el número de vecinos de cada punto\n","if vecindades is not None:\n","    print(f\"Epsilon-vecindades (eps={eps}):\")\n","    print(\"-\" * 40)\n","    for i, vecinos in enumerate(vecindades):\n","        print(f\"P{i}: {len(vecinos)} vecinos -> {list(vecinos)}\")"]},{"cell_type":"markdown","metadata":{"id":"Q8tAqN69VjlS"},"source":["### Tarea 1.2: Clasificación de Puntos\n","\n","Clasifique cada punto como núcleo, borde o ruido según los criterios de DBSCAN."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cb_jMH9uVjlT"},"outputs":[],"source":["# TODO: Clasificar cada punto\n","# Punto núcleo: |N_eps(p)| >= min_samples\n","# Punto borde: no es núcleo pero está en la vecindad de un núcleo\n","# Ruido: no es núcleo ni está en la vecindad de ningún núcleo\n","\n","tipos = []  # Lista para almacenar el tipo de cada punto\n","\n","# Su código aquí\n","\n","\n","# Mostrar clasificación\n","if len(tipos) > 0:\n","    print(\"Clasificación de puntos:\")\n","    print(\"-\" * 40)\n","    for i, tipo in enumerate(tipos):\n","        print(f\"P{i}: {tipo}\")"]},{"cell_type":"markdown","metadata":{"id":"WDjIZOysVjlU"},"source":["### Tarea 1.3: Verificación con DBSCAN de Scikit-learn\n","\n","Aplique DBSCAN y compare los resultados con su clasificación manual."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HiRRdJbgVjlV"},"outputs":[],"source":["# TODO: Aplicar DBSCAN y analizar los resultados\n","# Compare las etiquetas asignadas con su clasificación manual\n","\n","# Su código aquí\n","dbscan = None  # Reemplazar\n","labels = None  # Reemplazar\n","\n","if labels is not None:\n","    print(\"Resultados de DBSCAN:\")\n","    print(\"-\" * 40)\n","    for i, label in enumerate(labels):\n","        estado = \"Ruido\" if label == -1 else f\"Cluster {label}\"\n","        print(f\"P{i}: {estado}\")\n","\n","    # Identificar puntos núcleo\n","    print(f\"\\nÍndices de puntos núcleo: {dbscan.core_sample_indices_}\")"]},{"cell_type":"markdown","metadata":{"id":"mTXJrOTXVjlX"},"source":["### Pregunta de Reflexión 1\n","\n","Analice los resultados:\n","\n","1. ¿Cuántos clusters se formaron? ¿Coincide con lo que observa visualmente?\n","2. ¿El punto P8 (intermedio) fue clasificado como núcleo, borde o ruido? ¿Por qué?\n","3. ¿Qué pasaría si aumentamos eps a 1.0? ¿Y si lo reducimos a 0.4?\n","\n","*Escriba su respuesta aquí:*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"_ej8qdzvVjlX"},"source":["---\n","\n","## Ejercicio 2: Selección de Parámetros con k-Distance Graph\n","\n","### Contexto\n","\n","El método del k-distance graph es fundamental para seleccionar un valor apropiado de eps. En este ejercicio, aplicará esta técnica a diferentes datasets.\n","\n","### Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJ2EuA7nVjlY"},"outputs":[],"source":["# Generar dataset con estructura clara\n","X_ej2, y_ej2 = make_blobs(\n","    n_samples=300,\n","    centers=4,\n","    cluster_std=[0.5, 0.8, 0.6, 0.7],\n","    random_state=RANDOM_STATE\n",")\n","\n","# Añadir algunos outliers\n","outliers = np.random.uniform(low=-12, high=12, size=(15, 2))\n","X_ej2_noisy = np.vstack([X_ej2, outliers])\n","y_ej2_noisy = np.hstack([y_ej2, [-1]*15])\n","\n","plt.figure(figsize=(10, 6))\n","plt.scatter(X_ej2_noisy[:300, 0], X_ej2_noisy[:300, 1], c=y_ej2, cmap='viridis',\n","            edgecolors='w', s=50, alpha=0.7)\n","plt.scatter(X_ej2_noisy[300:, 0], X_ej2_noisy[300:, 1], c='red', marker='x',\n","            s=100, label='Outliers')\n","plt.xlabel('Característica 1')\n","plt.ylabel('Característica 2')\n","plt.title('Dataset para Ejercicio 2 (4 clusters + outliers)')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ioJSyf0NVjlY"},"source":["### Tarea 2.1: Implementar la Función k-Distance\n","\n","Implemente una función que calcule y grafique las k-distancias ordenadas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tRYRleDTVjlZ"},"outputs":[],"source":["def calcular_k_distance(X, k):\n","    \"\"\"\n","    Calcula la distancia al k-ésimo vecino más cercano para cada punto.\n","\n","    Parámetros:\n","    -----------\n","    X : array-like de forma (n_samples, n_features)\n","        Datos de entrada.\n","    k : int\n","        Número de vecinos a considerar.\n","\n","    Retorna:\n","    --------\n","    k_distances : array de forma (n_samples,)\n","        Distancias al k-ésimo vecino, ordenadas de menor a mayor.\n","    \"\"\"\n","    # TODO: Implementar la función\n","    # 1. Crear un objeto NearestNeighbors con n_neighbors=k\n","    # 2. Ajustar a los datos X\n","    # 3. Obtener las distancias con kneighbors\n","    # 4. Extraer la distancia al k-ésimo vecino (última columna)\n","    # 5. Ordenar de menor a mayor\n","\n","    # Su código aquí\n","    k_distances = None  # Reemplazar\n","\n","    return k_distances\n","\n","# Verificar la función\n","k = 5\n","k_dist = calcular_k_distance(X_ej2_noisy, k)\n","if k_dist is not None:\n","    print(f\"k-distances calculadas: {len(k_dist)} valores\")\n","    print(f\"Rango: [{k_dist.min():.3f}, {k_dist.max():.3f}]\")"]},{"cell_type":"markdown","metadata":{"id":"XumF3LmBVjlZ"},"source":["### Tarea 2.2: Graficar k-Distance y Encontrar el Codo\n","\n","Genere el gráfico de k-distancias e identifique el punto de inflexión (codo)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CRclmztaVjlZ"},"outputs":[],"source":["# TODO: Graficar k-distance para diferentes valores de k\n","fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n","\n","k_values = [3, 5, 10]\n","\n","for idx, k in enumerate(k_values):\n","    ax = axes[idx]\n","\n","    # TODO: Calcular k-distances y graficar\n","    # Su código aquí\n","\n","    ax.set_xlabel('Puntos ordenados')\n","    ax.set_ylabel(f'Distancia al {k}-ésimo vecino')\n","    ax.set_title(f'k-Distance Graph (k={k})')\n","    ax.grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"UoRewAEoVjla"},"source":["### Tarea 2.3: Aplicar DBSCAN con el eps Seleccionado\n","\n","Use el valor de eps identificado en el gráfico anterior."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iSjk0dvBVjlb"},"outputs":[],"source":["# TODO: Aplicar DBSCAN con el eps identificado\n","# Pruebe con el valor del codo que identificó\n","\n","eps_optimo = None  # Reemplazar con su valor\n","min_samples = 5\n","\n","if eps_optimo is not None:\n","    # Su código aquí\n","\n","    # Visualizar resultados\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"igG7XiweVjlb"},"source":["### Pregunta de Reflexión 2\n","\n","Analice el proceso de selección de parámetros:\n","\n","1. ¿El valor de eps identificado permitió detectar correctamente los 4 clusters?\n","2. ¿Cuántos outliers fueron detectados? ¿Coincide con los 15 que añadimos?\n","3. ¿Cómo afecta el valor de k a la forma de la curva y al eps sugerido?\n","\n","*Escriba su respuesta aquí:*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"_ecul11lVjlb"},"source":["---\n","\n","## Ejercicio 3: Comparación de Algoritmos en Estructuras No Convexas\n","\n","### Contexto\n","\n","Una ventaja clave de los métodos basados en densidad es su capacidad para detectar clusters de forma arbitraria. Compare el rendimiento de K-Means, DBSCAN y HDBSCAN.\n","\n","### Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cfilcwhZVjlc"},"outputs":[],"source":["# Generar datasets con diferentes estructuras\n","n_samples = 500\n","\n","# Dataset 1: Lunas\n","X_lunas, y_lunas = make_moons(n_samples=n_samples, noise=0.05, random_state=RANDOM_STATE)\n","\n","# Dataset 2: Círculos concéntricos\n","X_circulos, y_circulos = make_circles(n_samples=n_samples, noise=0.05, factor=0.5,\n","                                       random_state=RANDOM_STATE)\n","\n","# Dataset 3: Forma de S con ruido\n","t = np.linspace(0, 2*np.pi, n_samples//2)\n","x1 = np.sin(t) + np.random.normal(0, 0.1, len(t))\n","y1 = t + np.random.normal(0, 0.1, len(t))\n","x2 = np.sin(t) + 2 + np.random.normal(0, 0.1, len(t))\n","y2 = t + np.random.normal(0, 0.1, len(t))\n","X_s = np.vstack([np.column_stack([x1, y1]), np.column_stack([x2, y2])])\n","y_s = np.array([0]*len(t) + [1]*len(t))\n","\n","# Visualización\n","fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n","datasets = [(X_lunas, y_lunas, 'Lunas'), (X_circulos, y_circulos, 'Círculos'),\n","            (X_s, y_s, 'Forma de S')]\n","\n","for ax, (X, y, titulo) in zip(axes, datasets):\n","    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolors='w', s=30)\n","    ax.set_title(f'{titulo} (Ground Truth)')\n","    ax.set_xlabel('Característica 1')\n","    ax.set_ylabel('Característica 2')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"7hwaBrRBVjlc"},"source":["### Tarea 3.1: Aplicar K-Means a Cada Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YhqKEAKQVjlc"},"outputs":[],"source":["# TODO: Aplicar K-Means (k=2) a cada dataset y calcular ARI\n","fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n","\n","resultados_kmeans = []\n","\n","for idx, (X, y_true, titulo) in enumerate(datasets):\n","    ax = axes[idx]\n","\n","    # TODO: Aplicar K-Means\n","    # Su código aquí\n","\n","    ax.set_title(f'{titulo}')\n","    ax.set_xlabel('Característica 1')\n","    ax.set_ylabel('Característica 2')\n","\n","plt.suptitle('K-Means (k=2)', fontsize=14, fontweight='bold', y=1.02)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Z6MiAtmkVjld"},"source":["### Tarea 3.2: Aplicar DBSCAN con Parámetros Apropiados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Ia8BlT5Vjld"},"outputs":[],"source":["# TODO: Aplicar DBSCAN a cada dataset\n","# Seleccione eps apropiado para cada uno (puede usar k-distance)\n","\n","# Parámetros sugeridos para explorar:\n","# Lunas: eps entre 0.1 y 0.3\n","# Círculos: eps entre 0.1 y 0.3\n","# Forma S: eps entre 0.2 y 0.5\n","\n","fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n","\n","# TODO: Definir parámetros para cada dataset\n","params_dbscan = [\n","    {'eps': None, 'min_samples': 5},  # Lunas - Reemplazar eps\n","    {'eps': None, 'min_samples': 5},  # Círculos - Reemplazar eps\n","    {'eps': None, 'min_samples': 5}   # Forma S - Reemplazar eps\n","]\n","\n","resultados_dbscan = []\n","\n","for idx, (X, y_true, titulo) in enumerate(datasets):\n","    ax = axes[idx]\n","\n","    # TODO: Aplicar DBSCAN con los parámetros definidos\n","    # Su código aquí\n","\n","    ax.set_title(f'{titulo}')\n","    ax.set_xlabel('Característica 1')\n","    ax.set_ylabel('Característica 2')\n","\n","plt.suptitle('DBSCAN', fontsize=14, fontweight='bold', y=1.02)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"bmTIjMdRVjld"},"source":["### Tarea 3.3: Aplicar HDBSCAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8d5GdYBAVjle"},"outputs":[],"source":["# TODO: Aplicar HDBSCAN a cada dataset\n","fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n","\n","resultados_hdbscan = []\n","\n","for idx, (X, y_true, titulo) in enumerate(datasets):\n","    ax = axes[idx]\n","\n","    # TODO: Aplicar HDBSCAN con min_cluster_size=15\n","    # Su código aquí\n","\n","    ax.set_title(f'{titulo}')\n","    ax.set_xlabel('Característica 1')\n","    ax.set_ylabel('Característica 2')\n","\n","plt.suptitle('HDBSCAN', fontsize=14, fontweight='bold', y=1.02)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"zMPIV9mlVjle"},"source":["### Tarea 3.4: Tabla Comparativa de Resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-zpjgHGbVjle"},"outputs":[],"source":["# TODO: Crear una tabla comparativa con los ARI de cada algoritmo\n","\n","# Su código aquí para generar la tabla\n","# Formato sugerido:\n","# Dataset     | K-Means | DBSCAN | HDBSCAN\n","# Lunas       |   xxx   |  xxx   |   xxx\n","# Círculos    |   xxx   |  xxx   |   xxx\n","# Forma S     |   xxx   |  xxx   |   xxx"]},{"cell_type":"markdown","metadata":{"id":"POwPVPlbVjlf"},"source":["### Pregunta de Reflexión 3\n","\n","Basándose en los resultados:\n","\n","1. ¿Qué algoritmo tuvo mejor rendimiento general? ¿Por qué?\n","2. ¿En qué dataset K-Means tuvo peor rendimiento? Explique la razón.\n","3. ¿HDBSCAN requirió ajuste de parámetros? ¿Es esto una ventaja o desventaja?\n","\n","*Escriba su respuesta aquí:*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"lIVi8nL-Vjlf"},"source":["---\n","\n","## Ejercicio 4: HDBSCAN - Características Avanzadas\n","\n","### Contexto\n","\n","HDBSCAN proporciona información adicional como probabilidades de pertenencia y outlier scores. Explore estas características.\n","\n","### Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAwPWIGtVjlg"},"outputs":[],"source":["# Dataset con clusters de diferente densidad y outliers\n","np.random.seed(RANDOM_STATE)\n","\n","# Cluster denso\n","cluster_denso = np.random.randn(150, 2) * 0.3 + np.array([0, 0])\n","\n","# Cluster medio\n","cluster_medio = np.random.randn(100, 2) * 0.6 + np.array([4, 4])\n","\n","# Cluster disperso\n","cluster_disperso = np.random.randn(80, 2) * 1.2 + np.array([-4, 4])\n","\n","# Outliers\n","outliers = np.array([\n","    [6, -2], [-6, -2], [0, 7], [7, 7], [-7, 0],\n","    [3, -3], [-3, -3], [8, 2], [-8, 2], [0, -5]\n","])\n","\n","X_ej4 = np.vstack([cluster_denso, cluster_medio, cluster_disperso, outliers])\n","y_ej4 = np.array([0]*150 + [1]*100 + [2]*80 + [-1]*10)\n","\n","plt.figure(figsize=(10, 8))\n","for label in [0, 1, 2]:\n","    mask = y_ej4 == label\n","    plt.scatter(X_ej4[mask, 0], X_ej4[mask, 1], label=f'Cluster {label}',\n","                edgecolors='w', s=50, alpha=0.7)\n","plt.scatter(outliers[:, 0], outliers[:, 1], c='red', marker='x', s=100,\n","            label='Outliers', linewidths=2)\n","plt.xlabel('Característica 1')\n","plt.ylabel('Característica 2')\n","plt.title('Dataset con densidad variable y outliers')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"nfyXk3SeVjlg"},"source":["### Tarea 4.1: Aplicar HDBSCAN y Extraer Probabilidades"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZO52Jb7Vjlh"},"outputs":[],"source":["# TODO: Aplicar HDBSCAN y extraer probabilidades y outlier scores\n","\n","# Su código aquí\n","clusterer = None  # Reemplazar\n","labels_hdb = None  # Reemplazar\n","probabilidades = None  # Reemplazar (clusterer.probabilities_)\n","outlier_scores = None  # Reemplazar (clusterer.outlier_scores_)\n","\n","if labels_hdb is not None:\n","    n_clusters = len(set(labels_hdb)) - (1 if -1 in labels_hdb else 0)\n","    n_ruido = (labels_hdb == -1).sum()\n","    print(f\"Clusters encontrados: {n_clusters}\")\n","    print(f\"Puntos de ruido: {n_ruido}\")"]},{"cell_type":"markdown","metadata":{"id":"4j-LW1bIVjlh"},"source":["### Tarea 4.2: Visualizar Probabilidades de Pertenencia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZtTEy9FLVjli"},"outputs":[],"source":["# TODO: Crear visualización de probabilidades\n","fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n","\n","# Subplot 1: Clusters coloreados\n","ax = axes[0]\n","# Su código aquí\n","\n","# Subplot 2: Probabilidades de pertenencia\n","ax = axes[1]\n","# Su código aquí (usar colormap para mostrar probabilidades)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"FiZzDv97Vjlu"},"source":["### Tarea 4.3: Análisis de Outlier Scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ih6Xh3ETVjlv"},"outputs":[],"source":["# TODO: Identificar los puntos con mayor outlier score\n","# Compare con los outliers reales\n","\n","if outlier_scores is not None:\n","    # TODO: Encontrar los 10 puntos con mayor outlier score\n","    # Su código aquí\n","\n","    # Visualizar\n","    fig, ax = plt.subplots(figsize=(10, 8))\n","    # Su código aquí\n","\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ffgdUlbRVjlv"},"source":["### Pregunta de Reflexión 4\n","\n","Analice las características de HDBSCAN:\n","\n","1. ¿Las probabilidades de pertenencia son más bajas en los bordes de los clusters? ¿Por qué?\n","2. ¿HDBSCAN detectó correctamente los 10 outliers? ¿Hubo falsos positivos o negativos?\n","3. ¿Cómo podría usar los outlier scores en una aplicación de detección de fraude?\n","\n","*Escriba su respuesta aquí:*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"-u0tgONfVjlv"},"source":["---\n","\n","## Ejercicio 5: Caso Práctico - Segmentación de Clientes\n","\n","### Contexto\n","\n","Aplique métodos basados en densidad a un problema de segmentación de clientes usando datos de comportamiento de compra.\n","\n","### Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nvVZ2qhVjlw"},"outputs":[],"source":["# Simular datos de clientes\n","np.random.seed(RANDOM_STATE)\n","\n","n_clientes = 400\n","\n","# Segmento 1: Clientes frecuentes de bajo gasto\n","seg1_frecuencia = np.random.normal(25, 3, 100)  # Visitas/mes\n","seg1_gasto = np.random.normal(50, 10, 100)       # Gasto promedio\n","\n","# Segmento 2: Clientes ocasionales de alto gasto\n","seg2_frecuencia = np.random.normal(5, 2, 120)\n","seg2_gasto = np.random.normal(200, 30, 120)\n","\n","# Segmento 3: Clientes premium (alta frecuencia, alto gasto)\n","seg3_frecuencia = np.random.normal(20, 4, 80)\n","seg3_gasto = np.random.normal(300, 40, 80)\n","\n","# Segmento 4: Clientes inactivos (cluster disperso)\n","seg4_frecuencia = np.random.normal(2, 1.5, 80)\n","seg4_gasto = np.random.normal(30, 20, 80)\n","\n","# Clientes anómalos\n","anomalos_frecuencia = np.array([40, 1, 35, 50, 0.5])\n","anomalos_gasto = np.array([500, 600, 20, 400, 450])\n","\n","# Combinar datos\n","frecuencia = np.concatenate([seg1_frecuencia, seg2_frecuencia, seg3_frecuencia,\n","                             seg4_frecuencia, anomalos_frecuencia])\n","gasto = np.concatenate([seg1_gasto, seg2_gasto, seg3_gasto, seg4_gasto, anomalos_gasto])\n","\n","# Asegurar valores positivos\n","frecuencia = np.clip(frecuencia, 0.1, None)\n","gasto = np.clip(gasto, 10, None)\n","\n","# Crear DataFrame\n","df_clientes = pd.DataFrame({\n","    'frecuencia_mensual': frecuencia,\n","    'gasto_promedio': gasto,\n","    'segmento_real': [0]*100 + [1]*120 + [2]*80 + [3]*80 + [-1]*5\n","})\n","\n","print(f\"Dataset: {len(df_clientes)} clientes\")\n","print(f\"\\nEstadísticas descriptivas:\")\n","print(df_clientes[['frecuencia_mensual', 'gasto_promedio']].describe())"]},{"cell_type":"markdown","metadata":{"id":"iBQU0FzHVjlx"},"source":["### Tarea 5.1: Preprocesamiento y Exploración"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YFrBZjMiVjlx"},"outputs":[],"source":["# TODO: Estandarizar los datos y visualizar\n","\n","# Su código aquí\n","scaler = StandardScaler()\n","X_clientes = None  # Reemplazar\n","\n","# Visualización\n","if X_clientes is not None:\n","    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n","\n","    # Datos originales\n","    ax = axes[0]\n","    # Su código aquí\n","\n","    # Datos estandarizados\n","    ax = axes[1]\n","    # Su código aquí\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"42BPhmL6Vjly"},"source":["### Tarea 5.2: Selección de Parámetros para DBSCAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tRNo3CelVjly"},"outputs":[],"source":["# TODO: Usar k-distance para determinar eps\n","\n","# Su código aquí"]},{"cell_type":"markdown","metadata":{"id":"7icawGlKVjly"},"source":["### Tarea 5.3: Aplicar y Comparar Algoritmos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3DxI4la5Vjlz"},"outputs":[],"source":["# TODO: Aplicar K-Means, DBSCAN y HDBSCAN\n","# Comparar resultados\n","\n","fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n","\n","# Ground Truth\n","ax = axes[0, 0]\n","# Su código aquí\n","\n","# K-Means\n","ax = axes[0, 1]\n","# Su código aquí\n","\n","# DBSCAN\n","ax = axes[1, 0]\n","# Su código aquí\n","\n","# HDBSCAN\n","ax = axes[1, 1]\n","# Su código aquí\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"HwrNxzs2Vjlz"},"source":["### Tarea 5.4: Perfilado de Segmentos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Al7lngrxVjlz"},"outputs":[],"source":["# TODO: Crear perfiles de los segmentos encontrados por HDBSCAN\n","# Calcular estadísticas por segmento\n","\n","# Su código aquí"]},{"cell_type":"markdown","metadata":{"id":"NqZcSkUGVjl0"},"source":["### Pregunta de Reflexión 5\n","\n","Analice los resultados de la segmentación:\n","\n","1. ¿Qué algoritmo identificó mejor los segmentos de clientes? ¿Por qué?\n","2. ¿Se detectaron correctamente los clientes anómalos? ¿Qué caracteriza a estos clientes?\n","3. ¿Cómo describiría cada segmento en términos de negocio? ¿Qué estrategias de marketing sugeriría?\n","\n","*Escriba su respuesta aquí:*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"JwBcssncVjl0"},"source":["---\n","\n","## Ejercicio 6: Sensibilidad a la Dimensionalidad\n","\n","### Contexto\n","\n","Los métodos basados en densidad pueden verse afectados por la alta dimensionalidad. Explore este fenómeno.\n","\n","### Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fVFCNLLNVjl1"},"outputs":[],"source":["# Generar datos en diferentes dimensionalidades\n","def generar_datos_nd(n_samples, n_features, n_clusters, random_state=42):\n","    \"\"\"Genera datos con clusters en n dimensiones.\"\"\"\n","    X, y = make_blobs(n_samples=n_samples, n_features=n_features,\n","                      centers=n_clusters, random_state=random_state)\n","    return X, y\n","\n","# Crear datasets de diferentes dimensionalidades\n","dimensiones = [2, 5, 10, 20, 50]\n","datasets_dim = {}\n","\n","for d in dimensiones:\n","    X, y = generar_datos_nd(n_samples=300, n_features=d, n_clusters=3)\n","    datasets_dim[d] = (X, y)\n","    print(f\"Dimensión {d}: {X.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"gjIkwGbbVjl2"},"source":["### Tarea 6.1: Analizar Distribución de Distancias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9vk1qBjAVjl2"},"outputs":[],"source":["# TODO: Calcular y visualizar la distribución de distancias en cada dimensión\n","from scipy.spatial.distance import pdist\n","\n","fig, axes = plt.subplots(1, len(dimensiones), figsize=(18, 4))\n","\n","for idx, d in enumerate(dimensiones):\n","    ax = axes[idx]\n","    X, _ = datasets_dim[d]\n","\n","    # TODO: Calcular distancias y graficar histograma\n","    # Su código aquí\n","\n","    ax.set_title(f'd = {d}')\n","    ax.set_xlabel('Distancia')\n","\n","axes[0].set_ylabel('Frecuencia')\n","plt.suptitle('Distribución de distancias por dimensionalidad', fontsize=14, fontweight='bold')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"mF_jRxwRVjl3"},"source":["### Tarea 6.2: Rendimiento de DBSCAN vs Dimensionalidad"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCh_iZSFVjl3"},"outputs":[],"source":["# TODO: Aplicar DBSCAN a cada dataset y medir rendimiento\n","# Use un eps fijo y observe cómo cambia el resultado\n","\n","resultados_dim = []\n","\n","for d in dimensiones:\n","    X, y_true = datasets_dim[d]\n","\n","    # TODO: Aplicar DBSCAN\n","    # Calcular ARI y número de clusters/ruido\n","\n","    # Su código aquí\n","    pass\n","\n","# Mostrar resultados en tabla"]},{"cell_type":"markdown","metadata":{"id":"kmsLUa7tVjl4"},"source":["### Pregunta de Reflexión 6\n","\n","Analice el efecto de la dimensionalidad:\n","\n","1. ¿Cómo cambia la distribución de distancias al aumentar la dimensionalidad?\n","2. ¿Por qué DBSCAN tiene problemas en alta dimensionalidad?\n","3. ¿Qué estrategias podría usar para aplicar clustering basado en densidad a datos de alta dimensionalidad?\n","\n","*Escriba su respuesta aquí:*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"Z3eQiLLwVjmC"},"source":["---\n","\n","## Referencias\n","\n","- Ester, M., Kriegel, H. P., Sander, J., & Xu, X. (1996). A density-based algorithm for discovering clusters in large spatial databases with noise. *KDD*, 96(34), 226-231.\n","- Campello, R. J., Moulavi, D., & Sander, J. (2013). Density-based clustering based on hierarchical density estimates. *PAKDD*, 160-172.\n","- Scikit-learn documentation: https://scikit-learn.org/stable/modules/clustering.html\n","- HDBSCAN documentation: https://hdbscan.readthedocs.io/\n","\n","---\n","\n"]},{"cell_type":"markdown","source":["# EOF (End Of File)"],"metadata":{"id":"-B4aDn7AYn8u"}}]}