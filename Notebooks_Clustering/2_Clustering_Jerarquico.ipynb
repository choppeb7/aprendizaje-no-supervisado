{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["FRiuTkUhQWtk"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Clustering Jerárquico"],"metadata":{"id":"NBsTYDE5QasJ"}},{"cell_type":"markdown","metadata":{"id":"fXDkI3idQWth"},"source":["\n","## Métodos Aglomerativos y Divisivos\n","\n","### Objetivos del Notebook\n","\n","1. Comprender los fundamentos del clustering jerárquico y sus diferencias con métodos particionales\n","2. Implementar y comparar diferentes criterios de enlace (linkage)\n","3. Construir e interpretar dendrogramas para visualizar jerarquías de clusters\n","4. Aplicar técnicas de corte del dendrograma para determinar el número de clusters\n","5. Analizar la complejidad computacional y limitaciones de escalabilidad\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"FRiuTkUhQWtk"},"source":["## 1. Configuración del Entorno\n","\n","Importamos las bibliotecas necesarias para el desarrollo del módulo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rNL0G_bWQWtl"},"outputs":[],"source":["# Bibliotecas fundamentales\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","import time\n","\n","# Scipy: clustering jerárquico\n","from scipy.cluster.hierarchy import dendrogram, linkage, fcluster, cophenet\n","from scipy.spatial.distance import pdist, squareform\n","\n","# Scikit-learn\n","from sklearn.cluster import AgglomerativeClustering\n","from sklearn.datasets import make_blobs, make_moons\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import silhouette_score, adjusted_rand_score\n","\n","# Configuración de visualización\n","plt.style.use('seaborn-v0_8-whitegrid')\n","plt.rcParams['figure.figsize'] = (12, 6)\n","plt.rcParams['font.size'] = 11\n","plt.rcParams['axes.titlesize'] = 13\n","plt.rcParams['axes.labelsize'] = 11\n","\n","# Reproducibilidad\n","RANDOM_STATE = 42\n","np.random.seed(RANDOM_STATE)\n","\n","print(\"Entorno configurado correctamente.\")"]},{"cell_type":"markdown","metadata":{"id":"GxBB5oAFQWtn"},"source":["## 2. Fundamentos del Clustering Jerárquico\n","\n","El clustering jerárquico construye una jerarquía anidada de clusters, representable mediante una estructura de árbol llamada **dendrograma**. A diferencia de K-Means, no requiere especificar el número de clusters a priori.\n","\n","### 2.1 Generación de Datos de Ejemplo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AESs7mg7QWtn"},"outputs":[],"source":["# Generación de datos sintéticos\n","n_samples = 150\n","n_clusters_true = 4\n","\n","X, y_true = make_blobs(\n","    n_samples=n_samples,\n","    n_features=2,\n","    centers=n_clusters_true,\n","    cluster_std=0.8,\n","    random_state=RANDOM_STATE\n",")\n","\n","# Visualización\n","fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n","\n","axes[0].scatter(X[:, 0], X[:, 1], c='steelblue', alpha=0.6, edgecolors='w', s=60)\n","axes[0].set_xlabel('Característica 1')\n","axes[0].set_ylabel('Característica 2')\n","axes[0].set_title('Datos sin etiquetar (perspectiva no supervisada)')\n","\n","scatter = axes[1].scatter(X[:, 0], X[:, 1], c=y_true, cmap='viridis', alpha=0.6, edgecolors='w', s=60)\n","axes[1].set_xlabel('Característica 1')\n","axes[1].set_ylabel('Característica 2')\n","axes[1].set_title('Datos con etiquetas reales (ground truth)')\n","plt.colorbar(scatter, ax=axes[1], label='Cluster')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(f\"Dimensiones del dataset: {X.shape}\")\n","print(f\"Número de clusters reales: {n_clusters_true}\")"]},{"cell_type":"markdown","metadata":{"id":"pHFWel2OQWto"},"source":["### 2.2 Matriz de Distancias\n","\n","El clustering jerárquico opera sobre una matriz de distancias entre todos los pares de observaciones."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NyfovKklQWtp"},"outputs":[],"source":["# Calcular matriz de distancias (forma condensada y cuadrada)\n","distancias_condensadas = pdist(X, metric='euclidean')\n","matriz_distancias = squareform(distancias_condensadas)\n","\n","print(f\"Número de distancias únicas (forma condensada): {len(distancias_condensadas)}\")\n","print(f\"Fórmula: n(n-1)/2 = {n_samples}*{n_samples-1}/2 = {n_samples*(n_samples-1)//2}\")\n","print(f\"\\nDimensiones matriz cuadrada: {matriz_distancias.shape}\")\n","\n","# Visualización de la matriz de distancias (subconjunto)\n","fig, ax = plt.subplots(figsize=(8, 7))\n","im = ax.imshow(matriz_distancias[:50, :50], cmap='viridis')\n","ax.set_xlabel('Observación')\n","ax.set_ylabel('Observación')\n","ax.set_title('Matriz de distancias (primeras 50 observaciones)')\n","plt.colorbar(im, ax=ax, label='Distancia euclidiana')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"aLRezP9aQWtq"},"source":["## 3. Algoritmo Aglomerativo y Criterios de Enlace\n","\n","El enfoque aglomerativo (bottom-up) comienza con cada observación como un cluster individual y fusiona iterativamente los clusters más cercanos. El **criterio de enlace** define cómo se calcula la distancia entre clusters.\n","\n","### 3.1 Implementación con scipy.cluster.hierarchy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"COnyaAhlQWtr"},"outputs":[],"source":["# Calcular linkage con diferentes criterios\n","metodos_linkage = ['single', 'complete', 'average', 'ward']\n","resultados_linkage = {}\n","\n","for metodo in metodos_linkage:\n","    Z = linkage(X, method=metodo)\n","    resultados_linkage[metodo] = Z\n","    print(f\"Linkage '{metodo}' calculado. Dimensiones matriz Z: {Z.shape}\")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"La matriz Z tiene (n-1) filas, una por cada fusión.\")\n","print(\"Columnas: [cluster1, cluster2, distancia, tamaño_nuevo]\")"]},{"cell_type":"markdown","metadata":{"id":"t7J7tMf6QWts"},"source":["### 3.2 Estructura de la Matriz de Linkage\n","\n","La matriz Z contiene información sobre cada fusión realizada durante el clustering."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lv9aCmVBQWtt"},"outputs":[],"source":["# Examinar las primeras y últimas fusiones (método Ward)\n","Z_ward = resultados_linkage['ward']\n","\n","print(\"Primeras 5 fusiones (Ward):\")\n","print(f\"{'Fusión':<8} {'Cluster A':<12} {'Cluster B':<12} {'Distancia':<12} {'Tamaño':<10}\")\n","print(\"-\" * 54)\n","for i in range(5):\n","    print(f\"{i+1:<8} {int(Z_ward[i,0]):<12} {int(Z_ward[i,1]):<12} {Z_ward[i,2]:<12.4f} {int(Z_ward[i,3]):<10}\")\n","\n","print(\"\\nÚltimas 5 fusiones (Ward):\")\n","print(f\"{'Fusión':<8} {'Cluster A':<12} {'Cluster B':<12} {'Distancia':<12} {'Tamaño':<10}\")\n","print(\"-\" * 54)\n","for i in range(len(Z_ward)-5, len(Z_ward)):\n","    print(f\"{i+1:<8} {int(Z_ward[i,0]):<12} {int(Z_ward[i,1]):<12} {Z_ward[i,2]:<12.4f} {int(Z_ward[i,3]):<10}\")\n","\n","print(f\"\\nNota: Índices >= {n_samples} representan clusters formados en fusiones previas.\")"]},{"cell_type":"markdown","metadata":{"id":"Xl25WutoQWtt"},"source":["### 3.3 Visualización de Dendrogramas\n","\n","El dendrograma es la representación visual de la jerarquía de clusters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lUFrOzaXQWtu"},"outputs":[],"source":["# Dendrogramas para cada criterio de enlace\n","fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n","axes = axes.flatten()\n","\n","titulos = {\n","    'single': 'Single Linkage (Enlace Simple)',\n","    'complete': 'Complete Linkage (Enlace Completo)',\n","    'average': 'Average Linkage (UPGMA)',\n","    'ward': 'Ward\\'s Method'\n","}\n","\n","for idx, metodo in enumerate(metodos_linkage):\n","    ax = axes[idx]\n","    dendrogram(\n","        resultados_linkage[metodo],\n","        ax=ax,\n","        truncate_mode='lastp',\n","        p=30,\n","        leaf_rotation=90,\n","        leaf_font_size=8,\n","        show_contracted=True\n","    )\n","    ax.set_title(titulos[metodo], fontsize=12, fontweight='bold')\n","    ax.set_xlabel('Observaciones (o clusters)')\n","    ax.set_ylabel('Distancia de fusión')\n","\n","plt.suptitle('Comparación de Dendrogramas por Criterio de Enlace', fontsize=14, fontweight='bold', y=1.02)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"nRIu985mQWtu"},"source":["### 3.4 Análisis de Diferencias entre Criterios\n","\n","Cada criterio de enlace produce estructuras jerárquicas distintas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-52xPDdqQWtv"},"outputs":[],"source":["# Comparar particiones con k=4 para cada criterio\n","k = 4\n","\n","fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n","axes = axes.flatten()\n","\n","colores = ['#e74c3c', '#3498db', '#2ecc71', '#9b59b6']\n","\n","for idx, metodo in enumerate(metodos_linkage):\n","    ax = axes[idx]\n","\n","    # Obtener asignaciones cortando el dendrograma\n","    labels = fcluster(resultados_linkage[metodo], k, criterion='maxclust')\n","\n","    # Calcular silueta y ARI\n","    sil = silhouette_score(X, labels)\n","    ari = adjusted_rand_score(y_true, labels)\n","\n","    # Visualizar\n","    for cluster_id in range(1, k+1):\n","        mask = labels == cluster_id\n","        ax.scatter(X[mask, 0], X[mask, 1], c=colores[cluster_id-1],\n","                   alpha=0.6, edgecolors='w', s=60, label=f'Cluster {cluster_id}')\n","\n","    ax.set_title(f\"{titulos[metodo]}\\nSilueta: {sil:.3f} | ARI: {ari:.3f}\", fontsize=11)\n","    ax.set_xlabel('Característica 1')\n","    ax.set_ylabel('Característica 2')\n","    ax.legend(loc='best', fontsize=8)\n","\n","plt.suptitle(f'Particiones con k={k} clusters según criterio de enlace', fontsize=14, fontweight='bold', y=1.02)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"iGGGAqB2QWtv"},"source":["## 4. Interpretación del Dendrograma\n","\n","### 4.1 Lectura de la Altura y Selección del Corte"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qKrSbglNQWtv"},"outputs":[],"source":["# Dendrograma detallado con línea de corte (Ward)\n","fig, ax = plt.subplots(figsize=(14, 7))\n","\n","# Generar dendrograma\n","dend = dendrogram(\n","    Z_ward,\n","    ax=ax,\n","    truncate_mode='lastp',\n","    p=40,\n","    leaf_rotation=90,\n","    leaf_font_size=9,\n","    show_contracted=True,\n","    color_threshold=50\n",")\n","\n","# Añadir líneas de corte\n","ax.axhline(y=25, color='green', linestyle='--', linewidth=2, label='Corte para k=4')\n","ax.axhline(y=50, color='red', linestyle='--', linewidth=2, label='Corte para k=3')\n","ax.axhline(y=100, color='orange', linestyle='--', linewidth=2, label='Corte para k=2')\n","\n","ax.set_title('Dendrograma con líneas de corte (Ward)', fontsize=13, fontweight='bold')\n","ax.set_xlabel('Observaciones')\n","ax.set_ylabel('Distancia de fusión')\n","ax.legend(loc='upper right')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"Interpretación:\")\n","print(\"- La altura del nodo indica la distancia a la que se fusionan los clusters.\")\n","print(\"- Ramas verticales largas sugieren clusters bien separados.\")\n","print(\"- El corte horizontal determina el número de clusters resultantes.\")"]},{"cell_type":"markdown","metadata":{"id":"XPs7IMTCQWtw"},"source":["### 4.2 Análisis de Distancias de Fusión\n","\n","Identificar saltos en las distancias de fusión ayuda a determinar el número óptimo de clusters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ntog3HbEQWtw"},"outputs":[],"source":["# Extraer distancias de fusión\n","distancias_fusion = Z_ward[:, 2]\n","\n","# Calcular diferencias entre fusiones consecutivas\n","diferencias = np.diff(distancias_fusion)\n","\n","# Identificar los mayores saltos\n","n_top = 10\n","indices_mayores_saltos = np.argsort(diferencias)[-n_top:][::-1]\n","\n","fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n","\n","# Gráfico de distancias de fusión\n","axes[0].plot(range(1, len(distancias_fusion)+1), distancias_fusion, 'o-', markersize=3, linewidth=1)\n","axes[0].set_xlabel('Número de fusión')\n","axes[0].set_ylabel('Distancia de fusión')\n","axes[0].set_title('Evolución de distancias de fusión')\n","\n","# Gráfico de diferencias (análogo al método del codo)\n","# Mostrar desde las últimas 20 fusiones (donde suelen estar los saltos importantes)\n","ultimas_n = 20\n","x_axis = range(n_samples - ultimas_n, n_samples)\n","axes[1].bar(x_axis, diferencias[-ultimas_n:], color='steelblue', alpha=0.7)\n","axes[1].set_xlabel('Número de fusión')\n","axes[1].set_ylabel('Incremento en distancia')\n","axes[1].set_title(f'Diferencias entre fusiones (últimas {ultimas_n})')\n","\n","# Marcar el mayor salto\n","max_diff_idx = np.argmax(diferencias[-ultimas_n:])\n","axes[1].axvline(x=x_axis[max_diff_idx], color='red', linestyle='--',\n","                label=f'Mayor salto (k={n_samples - x_axis[max_diff_idx] + 1})') # Adjusted k value\n","axes[1].legend()\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(f\"\\nMayores saltos en distancia de fusión:\")\n","print(f\"{'Fusión':<10} {'Diferencia':<15} {'k resultante':<12}\")\n","print(\"-\" * 37)\n","for idx in indices_mayores_saltos[:5]:\n","    k_resultante = n_samples - idx - 1\n","    print(f\"{idx+1:<10} {diferencias[idx]:<15.4f} {k_resultante:<12}\")"]},{"cell_type":"markdown","metadata":{"id":"Zi8eyk1lQWtx"},"source":["### 4.3 Coeficiente de Correlación Cofenética\n","\n","Mide qué tan bien el dendrograma preserva las distancias originales entre observaciones."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2f3dDbiCQWtx"},"outputs":[],"source":["# Calcular correlación cofenética para cada método\n","print(\"Coeficiente de correlación cofenética por criterio de enlace:\")\n","print(\"=\" * 50)\n","print(f\"{'Criterio':<15} {'Correlación cofenética':<25}\")\n","print(\"-\" * 50)\n","\n","for metodo in metodos_linkage:\n","    c, coph_dists = cophenet(resultados_linkage[metodo], distancias_condensadas)\n","    print(f\"{metodo.capitalize():<15} {c:<25.4f}\")\n","\n","print(\"\\nInterpretación:\")\n","print(\"- Valores cercanos a 1 indican que el dendrograma preserva bien las distancias originales.\")\n","print(\"- Average linkage típicamente produce la mejor correlación cofenética.\")\n","print(\"- Ward optimiza varianza, no preservación de distancias.\")"]},{"cell_type":"markdown","metadata":{"id":"FTIJLsb_QWty"},"source":["## 5. Corte del Dendrograma\n","\n","### 5.1 Métodos de Corte con fcluster"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PosddEMtQWty"},"outputs":[],"source":["# Diferentes criterios de corte\n","print(\"Métodos de corte del dendrograma:\")\n","print(\"=\" * 60)\n","\n","# Por número de clusters\n","labels_maxclust = fcluster(Z_ward, t=4, criterion='maxclust')\n","print(f\"\\n1. criterion='maxclust', t=4\")\n","print(f\"   Clusters obtenidos: {len(np.unique(labels_maxclust))}\")\n","print(f\"   Distribución: {np.bincount(labels_maxclust)[1:]}\")\n","\n","# Por distancia\n","labels_distance = fcluster(Z_ward, t=50, criterion='distance')\n","print(f\"\\n2. criterion='distance', t=50\")\n","print(f\"   Clusters obtenidos: {len(np.unique(labels_distance))}\")\n","print(f\"   Distribución: {np.bincount(labels_distance)[1:]}\")\n","\n","# Por inconsistencia\n","labels_inconsistent = fcluster(Z_ward, t=1.5, criterion='inconsistent', depth=2)\n","print(f\"\\n3. criterion='inconsistent', t=1.5, depth=2\")\n","print(f\"   Clusters obtenidos: {len(np.unique(labels_inconsistent))}\")\n","print(f\"   Distribución: {np.bincount(labels_inconsistent)[1:]}\")"]},{"cell_type":"markdown","metadata":{"id":"rH2xMDdhQWty"},"source":["### 5.2 Selección Óptima del Número de Clusters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cNxanA_SQWty"},"outputs":[],"source":["# Evaluar silueta para diferentes valores de k\n","k_range = range(2, 11)\n","siluetas_ward = []\n","aris_ward = []\n","\n","for k in k_range:\n","    labels = fcluster(Z_ward, k, criterion='maxclust')\n","    siluetas_ward.append(silhouette_score(X, labels))\n","    aris_ward.append(adjusted_rand_score(y_true, labels))\n","\n","# Visualización\n","fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n","\n","# Silueta\n","axes[0].plot(k_range, siluetas_ward, 'o-', linewidth=2, markersize=8, color='steelblue')\n","axes[0].axvline(x=k_range[np.argmax(siluetas_ward)], color='red', linestyle='--',\n","                label=f'k óptimo = {k_range[np.argmax(siluetas_ward)]}')\n","axes[0].set_xlabel('Número de clusters (k)')\n","axes[0].set_ylabel('Coeficiente de Silueta')\n","axes[0].set_title('Selección de k por Silueta (Ward)')\n","axes[0].set_xticks(k_range)\n","axes[0].legend()\n","\n","# ARI (solo informativo, requiere ground truth)\n","axes[1].plot(k_range, aris_ward, 'o-', linewidth=2, markersize=8, color='#2ecc71')\n","axes[1].axvline(x=4, color='red', linestyle='--', label='k real = 4')\n","axes[1].set_xlabel('Número de clusters (k)')\n","axes[1].set_ylabel('Adjusted Rand Index')\n","axes[1].set_title('ARI vs Ground Truth (solo para validación)')\n","axes[1].set_xticks(k_range)\n","axes[1].legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"FOvom4sHQWtz"},"source":["## 6. Implementación con Scikit-learn\n","\n","Scikit-learn proporciona `AgglomerativeClustering` para clustering jerárquico."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"piaMUCJSQWtz"},"outputs":[],"source":["# Clustering con AgglomerativeClustering\n","modelo_ward = AgglomerativeClustering(\n","    n_clusters=4,\n","    linkage='ward'\n",")\n","\n","labels_sklearn = modelo_ward.fit_predict(X)\n","\n","# Comparar con scipy\n","labels_scipy = fcluster(Z_ward, 4, criterion='maxclust') - 1  # Ajustar índice base\n","\n","# Métricas\n","sil_sklearn = silhouette_score(X, labels_sklearn)\n","sil_scipy = silhouette_score(X, labels_scipy)\n","\n","print(\"Comparación scipy vs scikit-learn:\")\n","print(f\"{'Implementación':<20} {'Silueta':<15}\")\n","print(\"-\" * 35)\n","print(f\"{'scipy.hierarchy':<20} {sil_scipy:<15.4f}\")\n","print(f\"{'sklearn':<20} {sil_sklearn:<15.4f}\")\n","\n","# Verificar concordancia\n","concordancia = adjusted_rand_score(labels_scipy, labels_sklearn)\n","print(f\"\\nARI entre ambas implementaciones: {concordancia:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ebRTaGvSQWtz"},"outputs":[],"source":["# Comparación de todos los criterios con sklearn\n","linkages_sklearn = ['ward', 'complete', 'average', 'single']\n","\n","fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n","axes = axes.flatten()\n","\n","for idx, linkage_method in enumerate(linkages_sklearn):\n","    ax = axes[idx]\n","\n","    modelo = AgglomerativeClustering(n_clusters=4, linkage=linkage_method)\n","    labels = modelo.fit_predict(X)\n","\n","    sil = silhouette_score(X, labels)\n","    ari = adjusted_rand_score(y_true, labels)\n","\n","    for cluster_id in range(4):\n","        mask = labels == cluster_id\n","        ax.scatter(X[mask, 0], X[mask, 1], c=colores[cluster_id],\n","                   alpha=0.6, edgecolors='w', s=60)\n","\n","    ax.set_title(f\"{linkage_method.capitalize()} Linkage\\nSilueta: {sil:.3f} | ARI: {ari:.3f}\")\n","    ax.set_xlabel('Característica 1')\n","    ax.set_ylabel('Característica 2')\n","\n","plt.suptitle('Clustering Jerárquico con scikit-learn', fontsize=14, fontweight='bold', y=1.02)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZEg57jtgQWt0"},"source":["## 7. Comportamiento con Diferentes Estructuras de Datos\n","\n","### 7.1 Clusters No Esféricos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZG_7t1ceQWt0"},"outputs":[],"source":["# Generar datos con forma de lunas\n","X_moons, y_moons = make_moons(n_samples=200, noise=0.05, random_state=RANDOM_STATE)\n","\n","# Aplicar diferentes criterios de enlace\n","fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n","\n","# Ground truth\n","axes[0, 0].scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons, cmap='viridis',\n","                   edgecolors='w', s=60)\n","axes[0, 0].set_title('Ground Truth', fontsize=11, fontweight='bold')\n","axes[0, 0].set_xlabel('Característica 1')\n","axes[0, 0].set_ylabel('Característica 2')\n","\n","# Aplicar cada criterio\n","for idx, (linkage_method, ax) in enumerate(zip(['single', 'complete', 'average', 'ward'],\n","                                                [axes[0,1], axes[0,2], axes[1,0], axes[1,1]])):\n","    modelo = AgglomerativeClustering(n_clusters=2, linkage=linkage_method)\n","    labels = modelo.fit_predict(X_moons)\n","\n","    ari = adjusted_rand_score(y_moons, labels)\n","\n","    ax.scatter(X_moons[:, 0], X_moons[:, 1], c=labels, cmap='viridis',\n","               edgecolors='w', s=60)\n","    ax.set_title(f\"{linkage_method.capitalize()} (ARI: {ari:.3f})\", fontsize=11)\n","    ax.set_xlabel('Característica 1')\n","    ax.set_ylabel('Característica 2')\n","\n","# Ocultar último subplot vacío\n","axes[1, 2].axis('off')\n","axes[1, 2].text(0.5, 0.5, 'Single linkage\\ndetecta correctamente\\nlas formas no convexas',\n","                ha='center', va='center', fontsize=12, style='italic',\n","                bbox=dict(boxstyle='round', facecolor='#edf2f7', alpha=0.8))\n","\n","plt.suptitle('Clustering Jerárquico con Clusters No Esféricos', fontsize=14, fontweight='bold', y=1.02)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"RJlcgGBQQWt0"},"source":["### 7.2 Efecto Cadena (Chaining) en Single Linkage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Ul2wcwXQWt1"},"outputs":[],"source":["# Crear datos que demuestren el efecto cadena\n","np.random.seed(RANDOM_STATE)\n","\n","# Dos clusters bien definidos con un \"puente\" de puntos\n","cluster1 = np.random.randn(50, 2) * 0.5 + np.array([-3, 0])\n","cluster2 = np.random.randn(50, 2) * 0.5 + np.array([3, 0])\n","puente = np.column_stack([np.linspace(-2.5, 2.5, 10), np.random.randn(10) * 0.1])\n","\n","X_cadena = np.vstack([cluster1, cluster2, puente])\n","y_cadena = np.array([0]*50 + [1]*50 + [2]*10)  # El puente como \"ruido\"\n","\n","fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n","\n","# Datos originales\n","axes[0].scatter(cluster1[:, 0], cluster1[:, 1], c='#3498db', alpha=0.6, edgecolors='w', s=60, label='Cluster 1')\n","axes[0].scatter(cluster2[:, 0], cluster2[:, 1], c='#e74c3c', alpha=0.6, edgecolors='w', s=60, label='Cluster 2')\n","axes[0].scatter(puente[:, 0], puente[:, 1], c='#2ecc71', alpha=0.8, edgecolors='w', s=80, marker='s', label='Puente (ruido)')\n","axes[0].set_title('Datos originales', fontsize=11, fontweight='bold')\n","axes[0].legend()\n","axes[0].set_xlabel('Característica 1')\n","axes[0].set_ylabel('Característica 2')\n","\n","# Single linkage\n","modelo_single = AgglomerativeClustering(n_clusters=2, linkage='single')\n","labels_single = modelo_single.fit_predict(X_cadena)\n","axes[1].scatter(X_cadena[:, 0], X_cadena[:, 1], c=labels_single, cmap='coolwarm',\n","                alpha=0.6, edgecolors='w', s=60)\n","axes[1].set_title(f'Single Linkage (efecto cadena)', fontsize=11, fontweight='bold')\n","axes[1].set_xlabel('Característica 1')\n","axes[1].set_ylabel('Característica 2')\n","\n","# Ward\n","modelo_ward = AgglomerativeClustering(n_clusters=2, linkage='ward')\n","labels_ward = modelo_ward.fit_predict(X_cadena)\n","axes[2].scatter(X_cadena[:, 0], X_cadena[:, 1], c=labels_ward, cmap='coolwarm',\n","                alpha=0.6, edgecolors='w', s=60)\n","axes[2].set_title(f'Ward (resistente a cadena)', fontsize=11, fontweight='bold')\n","axes[2].set_xlabel('Característica 1')\n","axes[2].set_ylabel('Característica 2')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"El efecto cadena de single linkage hace que los clusters\")\n","print(\"se fusionen prematuramente cuando existen puntos intermedios.\")"]},{"cell_type":"markdown","metadata":{"id":"g-q_7x03QWt1"},"source":["## 8. Análisis de Complejidad Computacional\n","\n","El clustering jerárquico tiene una complejidad temporal de O(n² log n) y espacial de O(n²), lo que limita su aplicabilidad a datasets grandes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"de6DktjGQWt2"},"outputs":[],"source":["# Medir tiempo de ejecución para diferentes tamaños de dataset\n","tamanos = [100, 500, 1000, 2000, 3000, 5000]\n","tiempos_scipy = []\n","tiempos_sklearn = []\n","\n","print(\"Midiendo tiempos de ejecución...\")\n","print(f\"{'n':<10} {'scipy (s)':<15} {'sklearn (s)':<15}\")\n","print(\"-\" * 40)\n","\n","for n in tamanos:\n","    X_temp, _ = make_blobs(n_samples=n, n_features=2, centers=4, random_state=RANDOM_STATE)\n","\n","    # scipy\n","    inicio = time.time()\n","    Z_temp = linkage(X_temp, method='ward')\n","    tiempo_scipy = time.time() - inicio\n","    tiempos_scipy.append(tiempo_scipy)\n","\n","    # sklearn\n","    inicio = time.time()\n","    modelo = AgglomerativeClustering(n_clusters=4, linkage='ward')\n","    modelo.fit(X_temp)\n","    tiempo_sklearn = time.time() - inicio\n","    tiempos_sklearn.append(tiempo_sklearn)\n","\n","    print(f\"{n:<10} {tiempo_scipy:<15.4f} {tiempo_sklearn:<15.4f}\")\n","\n","# Visualización\n","fig, ax = plt.subplots(figsize=(10, 6))\n","\n","ax.plot(tamanos, tiempos_scipy, 'o-', linewidth=2, markersize=8, label='scipy.hierarchy.linkage')\n","ax.plot(tamanos, tiempos_sklearn, 's-', linewidth=2, markersize=8, label='sklearn.AgglomerativeClustering')\n","\n","ax.set_xlabel('Número de observaciones (n)')\n","ax.set_ylabel('Tiempo de ejecución (segundos)')\n","ax.set_title('Escalabilidad del Clustering Jerárquico')\n","ax.legend()\n","ax.grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"\\nNota: Para n > 10,000, considerar métodos alternativos como:\")\n","print(\"- Mini-Batch K-Means\")\n","print(\"- BIRCH (pre-clustering)\")\n","print(\"- Muestreo + clustering jerárquico\")"]},{"cell_type":"markdown","metadata":{"id":"6QnJHhGnQWt3"},"source":["## 9. Caso Práctico: Taxonomía de Productos\n","\n","Aplicamos clustering jerárquico para crear una taxonomía de productos basada en sus características."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvv78OWxQWt3"},"outputs":[],"source":["# Simular datos de productos\n","np.random.seed(RANDOM_STATE)\n","\n","# Características de productos\n","productos = {\n","    'Producto': [f'P{i:02d}' for i in range(1, 31)],\n","    'Precio': np.concatenate([\n","        np.random.uniform(10, 50, 10),      # Económicos\n","        np.random.uniform(50, 150, 10),     # Gama media\n","        np.random.uniform(150, 500, 10)     # Premium\n","    ]),\n","    'Peso_kg': np.concatenate([\n","        np.random.uniform(0.1, 1, 10),\n","        np.random.uniform(1, 5, 10),\n","        np.random.uniform(5, 20, 10)\n","    ]),\n","    'Rating': np.concatenate([\n","        np.random.uniform(3.0, 4.0, 10),\n","        np.random.uniform(3.5, 4.5, 10),\n","        np.random.uniform(4.0, 5.0, 10)\n","    ]),\n","    'Ventas_mes': np.concatenate([\n","        np.random.poisson(500, 10),\n","        np.random.poisson(200, 10),\n","        np.random.poisson(50, 10)\n","    ])\n","}\n","\n","df_productos = pd.DataFrame(productos)\n","print(\"Dataset de productos:\")\n","print(df_productos.head(10))\n","print(f\"\\nDimensiones: {df_productos.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kQf6sAbQWt4"},"outputs":[],"source":["# Preprocesamiento\n","features = ['Precio', 'Peso_kg', 'Rating', 'Ventas_mes']\n","X_productos = df_productos[features].values\n","\n","scaler = StandardScaler()\n","X_productos_scaled = scaler.fit_transform(X_productos)\n","\n","# Clustering jerárquico\n","Z_productos = linkage(X_productos_scaled, method='ward')\n","\n","# Dendrograma con nombres de productos\n","fig, ax = plt.subplots(figsize=(16, 8))\n","\n","dendrogram(\n","    Z_productos,\n","    ax=ax,\n","    labels=df_productos['Producto'].values,\n","    leaf_rotation=90,\n","    leaf_font_size=10,\n","    color_threshold=4\n",")\n","\n","ax.axhline(y=4, color='red', linestyle='--', linewidth=2, label='Corte sugerido')\n","ax.set_title('Taxonomía de Productos (Clustering Jerárquico - Ward)', fontsize=13, fontweight='bold')\n","ax.set_xlabel('Productos')\n","ax.set_ylabel('Distancia de fusión')\n","ax.legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJdDTDK3QWt4"},"outputs":[],"source":["# Asignar categorías\n","df_productos['Categoria'] = fcluster(Z_productos, t=3, criterion='maxclust')\n","\n","# Perfilar categorías\n","print(\"Perfil de categorías de productos:\")\n","print(\"=\" * 70)\n","\n","for cat in sorted(df_productos['Categoria'].unique()):\n","    datos_cat = df_productos[df_productos['Categoria'] == cat]\n","    print(f\"\\nCategoría {cat} ({len(datos_cat)} productos):\")\n","    print(f\"  Precio promedio:  ${datos_cat['Precio'].mean():.2f} (${datos_cat['Precio'].min():.2f} - ${datos_cat['Precio'].max():.2f})\")\n","    print(f\"  Peso promedio:    {datos_cat['Peso_kg'].mean():.2f} kg\")\n","    print(f\"  Rating promedio:  {datos_cat['Rating'].mean():.2f}\")\n","    print(f\"  Ventas promedio:  {datos_cat['Ventas_mes'].mean():.0f} unidades/mes\")\n","    print(f\"  Productos:        {', '.join(datos_cat['Producto'].values)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7mE2EMgQWt5"},"outputs":[],"source":["# Visualización de categorías\n","fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n","\n","colores_cat = ['#e74c3c', '#3498db', '#2ecc71']\n","\n","# Precio vs Peso\n","for cat in sorted(df_productos['Categoria'].unique()):\n","    mask = df_productos['Categoria'] == cat\n","    axes[0].scatter(df_productos.loc[mask, 'Precio'],\n","                    df_productos.loc[mask, 'Peso_kg'],\n","                    c=colores_cat[cat-1], label=f'Categoría {cat}',\n","                    alpha=0.7, edgecolors='w', s=80)\n","axes[0].set_xlabel('Precio ($)')\n","axes[0].set_ylabel('Peso (kg)')\n","axes[0].set_title('Precio vs Peso')\n","axes[0].legend()\n","\n","# Precio vs Ventas\n","for cat in sorted(df_productos['Categoria'].unique()):\n","    mask = df_productos['Categoria'] == cat\n","    axes[1].scatter(df_productos.loc[mask, 'Precio'],\n","                    df_productos.loc[mask, 'Ventas_mes'],\n","                    c=colores_cat[cat-1], label=f'Categoría {cat}',\n","                    alpha=0.7, edgecolors='w', s=80)\n","axes[1].set_xlabel('Precio ($)')\n","axes[1].set_ylabel('Ventas mensuales')\n","axes[1].set_title('Precio vs Ventas')\n","axes[1].legend()\n","\n","# Rating vs Ventas\n","for cat in sorted(df_productos['Categoria'].unique()):\n","    mask = df_productos['Categoria'] == cat\n","    axes[2].scatter(df_productos.loc[mask, 'Rating'],\n","                    df_productos.loc[mask, 'Ventas_mes'],\n","                    c=colores_cat[cat-1], label=f'Categoría {cat}',\n","                    alpha=0.7, edgecolors='w', s=80)\n","axes[2].set_xlabel('Rating')\n","axes[2].set_ylabel('Ventas mensuales')\n","axes[2].set_title('Rating vs Ventas')\n","axes[2].legend()\n","\n","plt.suptitle('Visualización de Categorías de Productos', fontsize=14, fontweight='bold', y=1.02)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Jtp08HigQWuA"},"source":["## 10. Resumen y Conclusiones\n","\n","### Conceptos Clave\n","\n","1. **Clustering jerárquico** construye una estructura anidada de clusters sin requerir k a priori, visualizable mediante dendrogramas.\n","\n","2. **Criterios de enlace** determinan cómo se calcula la distancia entre clusters:\n","   - **Single:** Formas arbitrarias, sensible al efecto cadena.\n","   - **Complete:** Clusters compactos, control de diámetro.\n","   - **Average:** Balance intermedio, buena correlación cofenética.\n","   - **Ward:** Minimiza varianza, similar a K-Means.\n","\n","3. **Selección del corte:** Analizar saltos en distancias de fusión, usar métricas de validación (silueta), o especificar k directamente.\n","\n","4. **Escalabilidad:** Limitado a datasets medianos (n < 10,000) debido a complejidad O(n² log n) y memoria O(n²).\n","\n","### Criterios de Selección\n","\n","| Situación | Recomendación |\n","|-----------|---------------|\n","| Exploración inicial | Ward o Average |\n","| Clusters elongados | Single linkage |\n","| Control de tamaño | Complete linkage |\n","| Dataset grande (n > 10k) | K-Means o BIRCH |\n","| Taxonomías/filogenias | Average (UPGMA) |"]},{"cell_type":"markdown","metadata":{"id":"30h0EB6WQWuB"},"source":["---\n","\n","## Referencias\n","\n","- Johnson, S. C. (1967). Hierarchical clustering schemes. *Psychometrika*, 32(3), 241-254.\n","- Ward Jr, J. H. (1963). Hierarchical grouping to optimize an objective function. *Journal of the American Statistical Association*, 58(301), 236-244.\n","- Sokal, R. R., & Michener, C. D. (1958). A statistical method for evaluating systematic relationships. *University of Kansas Science Bulletin*, 38, 1409-1438.\n","- Scipy documentation: https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html\n","- Scikit-learn documentation: https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering\n","\n","---\n"]},{"cell_type":"markdown","source":["# EOF (End Of File)"],"metadata":{"id":"RdNwfkMpVTkN"}}]}