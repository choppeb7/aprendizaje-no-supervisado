{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["ijhLpTSEOrtC","HrQ50uOhOrtM","1zKbufuiOrtN"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Métodos Basados en Modelos y Otros Algoritmos - Ejercicios"],"metadata":{"id":"7Q-rgi1mPAHy"}},{"cell_type":"markdown","metadata":{"id":"mRhZXqw-Ors8"},"source":["\n","---\n","Este notebook contiene ejercicios prácticos para consolidar los conceptos del Módulo 5."]},{"cell_type":"markdown","metadata":{"id":"ijhLpTSEOrtC"},"source":["## Configuración Inicial"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C_qQ6LZdOrtD"},"outputs":[],"source":["# Importar bibliotecas necesarias\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Ellipse\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Scikit-learn\n","from sklearn.mixture import GaussianMixture\n","from sklearn.cluster import (\n","    SpectralClustering, MeanShift, AffinityPropagation, Birch, KMeans\n",")\n","from sklearn.cluster import estimate_bandwidth\n","from sklearn.datasets import make_blobs, make_moons, make_circles\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import adjusted_rand_score, silhouette_score\n","\n","# Configuración\n","plt.style.use('seaborn-v0_8-whitegrid')\n","plt.rcParams['figure.figsize'] = (12, 5)\n","plt.rcParams['font.size'] = 11\n","\n","RANDOM_STATE = 42\n","np.random.seed(RANDOM_STATE)\n","\n","print(\"Entorno configurado correctamente.\")"]},{"cell_type":"markdown","metadata":{"id":"lSKxSnLOOrtF"},"source":["---\n","\n","## Ejercicio 1: Tipos de Covarianza en GMM\n","\n","### Objetivo\n","Comprender cómo los diferentes tipos de covarianza afectan la capacidad de GMM para modelar clusters de distintas formas.\n","\n","### Contexto\n","Se proporciona un dataset con clusters elípticos. Debe ajustar GMM con diferentes tipos de covarianza y comparar los resultados."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJbJO9XrOrtG"},"outputs":[],"source":["# Generar dataset con clusters elípticos\n","np.random.seed(RANDOM_STATE)\n","\n","# Cluster 1: elipse horizontal\n","n1 = 150\n","cluster1 = np.random.multivariate_normal([0, 0], [[2.0, 0], [0, 0.3]], n1)\n","\n","# Cluster 2: elipse vertical\n","n2 = 150\n","cluster2 = np.random.multivariate_normal([4, 0], [[0.3, 0], [0, 2.0]], n2)\n","\n","# Cluster 3: elipse diagonal\n","n3 = 150\n","theta = np.pi / 4\n","rot = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n","cov3 = rot @ np.array([[1.5, 0], [0, 0.3]]) @ rot.T\n","cluster3 = np.random.multivariate_normal([2, 3], cov3, n3)\n","\n","X_ej1 = np.vstack([cluster1, cluster2, cluster3])\n","y_ej1 = np.array([0]*n1 + [1]*n2 + [2]*n3)\n","\n","# Visualizar datos\n","plt.figure(figsize=(8, 6))\n","plt.scatter(X_ej1[:, 0], X_ej1[:, 1], c=y_ej1, cmap='viridis', edgecolors='w', s=40)\n","plt.title('Dataset con clusters elípticos de diferentes orientaciones')\n","plt.xlabel('X1')\n","plt.ylabel('X2')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YqLd5WXSOrtG"},"outputs":[],"source":["# =============================================================================\n","# EJERCICIO 1: Completar el código\n","# =============================================================================\n","\n","# Lista de tipos de covarianza a evaluar\n","tipos_covarianza = ['spherical', 'diag', 'tied', 'full']\n","\n","# Almacenar resultados\n","resultados_ej1 = []\n","\n","fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n","\n","for ax, cov_type in zip(axes, tipos_covarianza):\n","    # TODO: Crear un modelo GMM con:\n","    #   - n_components=3\n","    #   - covariance_type=cov_type\n","    #   - random_state=RANDOM_STATE\n","    gmm = None  # Completar\n","\n","    # TODO: Ajustar el modelo y obtener las etiquetas predichas\n","    labels = None  # Completar\n","\n","    # TODO: Calcular el ARI comparando con y_ej1\n","    ari = None  # Completar\n","\n","    # TODO: Obtener el BIC del modelo\n","    bic = None  # Completar\n","\n","    # Guardar resultados\n","    resultados_ej1.append({\n","        'tipo': cov_type,\n","        'ari': ari,\n","        'bic': bic\n","    })\n","\n","    # Visualizar\n","    ax.scatter(X_ej1[:, 0], X_ej1[:, 1], c=labels, cmap='viridis',\n","               edgecolors='w', s=30)\n","    ax.set_title(f'{cov_type}\\nARI: {ari:.3f}')\n","    ax.set_xlabel('X1')\n","    ax.set_ylabel('X2')\n","\n","plt.suptitle('Comparación de tipos de covarianza en GMM', fontsize=13, fontweight='bold')\n","plt.tight_layout()\n","plt.show()\n","\n","# Mostrar tabla de resultados\n","print(\"\\nResultados:\")\n","print(\"-\" * 40)\n","print(f\"{'Tipo':<12} {'ARI':<10} {'BIC':<15}\")\n","print(\"-\" * 40)\n","for r in resultados_ej1:\n","    print(f\"{r['tipo']:<12} {r['ari']:<10.4f} {r['bic']:<15.1f}\")"]},{"cell_type":"markdown","metadata":{"id":"iMq3R6yTOrtH"},"source":["### Preguntas de reflexión - Ejercicio 1\n","\n","1. ¿Por qué el tipo 'spherical' obtiene peores resultados en este dataset?\n","2. ¿Qué tipo de covarianza tiene el menor BIC? ¿Coincide con el mejor ARI?\n","3. ¿En qué situaciones sería preferible usar 'diag' en lugar de 'full'?"]},{"cell_type":"markdown","metadata":{"id":"IqfWRVDGOrtI"},"source":["---\n","\n","## Ejercicio 2: Selección del Número de Componentes\n","\n","### Objetivo\n","Aplicar BIC y AIC para determinar el número óptimo de componentes en un GMM.\n","\n","### Contexto\n","Se proporciona un dataset donde el número real de clusters no es evidente. Debe implementar la selección de K mediante criterios de información."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"On1IN3PxOrtJ"},"outputs":[],"source":["# Generar dataset con número de clusters oculto\n","np.random.seed(RANDOM_STATE)\n","\n","X_ej2, y_ej2 = make_blobs(n_samples=400, centers=4, cluster_std=1.2,\n","                          random_state=RANDOM_STATE)\n","\n","# Visualizar sin etiquetas\n","plt.figure(figsize=(8, 6))\n","plt.scatter(X_ej2[:, 0], X_ej2[:, 1], c='gray', edgecolors='w', s=40, alpha=0.7)\n","plt.title('Dataset para selección de K (etiquetas ocultas)')\n","plt.xlabel('X1')\n","plt.ylabel('X2')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bGqJEOIVOrtJ"},"outputs":[],"source":["# =============================================================================\n","# EJERCICIO 2: Completar el código\n","# =============================================================================\n","\n","# Rango de componentes a evaluar\n","rango_k = range(1, 10)\n","\n","# Listas para almacenar BIC y AIC\n","valores_bic = []\n","valores_aic = []\n","\n","for k in rango_k:\n","    # TODO: Crear y ajustar un GMM con k componentes\n","    gmm = None  # Completar\n","\n","    # TODO: Calcular y almacenar BIC\n","    bic = None  # Completar\n","    valores_bic.append(bic)\n","\n","    # TODO: Calcular y almacenar AIC\n","    aic = None  # Completar\n","    valores_aic.append(aic)\n","\n","# TODO: Encontrar el K óptimo según BIC (el que minimiza BIC)\n","k_optimo_bic = None  # Completar\n","\n","# TODO: Encontrar el K óptimo según AIC\n","k_optimo_aic = None  # Completar\n","\n","# Visualización\n","fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n","\n","# Gráfico BIC/AIC\n","ax = axes[0]\n","ax.plot(list(rango_k), valores_bic, 'b-o', linewidth=2, markersize=8, label='BIC')\n","ax.plot(list(rango_k), valores_aic, 'r--s', linewidth=2, markersize=8, label='AIC')\n","ax.axvline(x=k_optimo_bic, color='blue', linestyle=':', alpha=0.7)\n","ax.axvline(x=k_optimo_aic, color='red', linestyle=':', alpha=0.7)\n","ax.set_xlabel('Número de componentes (K)')\n","ax.set_ylabel('Valor del criterio')\n","ax.set_title('Selección de K con BIC y AIC')\n","ax.legend()\n","ax.grid(True, alpha=0.3)\n","\n","# Clustering con K óptimo\n","ax = axes[1]\n","gmm_optimo = GaussianMixture(n_components=k_optimo_bic, random_state=RANDOM_STATE)\n","labels_optimo = gmm_optimo.fit_predict(X_ej2)\n","ari_optimo = adjusted_rand_score(y_ej2, labels_optimo)\n","ax.scatter(X_ej2[:, 0], X_ej2[:, 1], c=labels_optimo, cmap='viridis',\n","           edgecolors='w', s=40)\n","ax.set_title(f'GMM con K={k_optimo_bic} (BIC óptimo)\\nARI: {ari_optimo:.3f}')\n","ax.set_xlabel('X1')\n","ax.set_ylabel('X2')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(f\"\\nK óptimo según BIC: {k_optimo_bic}\")\n","print(f\"K óptimo según AIC: {k_optimo_aic}\")\n","print(f\"K real: 4\")"]},{"cell_type":"markdown","metadata":{"id":"8pGgj4vbOrtK"},"source":["### Preguntas de reflexión - Ejercicio 2\n","\n","1. ¿Por qué BIC tiende a seleccionar modelos más simples que AIC?\n","2. Si BIC y AIC sugieren valores diferentes de K, ¿cuál debería elegir y por qué?\n","3. ¿Qué sucedería si el dataset tuviera clusters de tamaños muy diferentes?"]},{"cell_type":"markdown","metadata":{"id":"v5EGCYHrOrtK"},"source":["---\n","\n","## Ejercicio 3: Soft Clustering con GMM\n","\n","### Objetivo\n","Explorar las probabilidades de pertenencia (soft clustering) y su utilidad para identificar puntos ambiguos.\n","\n","### Contexto\n","Se proporciona un dataset con clusters que se solapan parcialmente. Debe analizar las probabilidades de pertenencia para identificar puntos con alta incertidumbre."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xx8_j4FOrtL"},"outputs":[],"source":["# Generar dataset con clusters solapados\n","np.random.seed(RANDOM_STATE)\n","\n","# Dos clusters cercanos que se solapan\n","X_ej3, y_ej3 = make_blobs(n_samples=300, centers=[[0, 0], [2, 0]],\n","                          cluster_std=0.9, random_state=RANDOM_STATE)\n","\n","plt.figure(figsize=(8, 6))\n","plt.scatter(X_ej3[:, 0], X_ej3[:, 1], c=y_ej3, cmap='coolwarm',\n","            edgecolors='w', s=40)\n","plt.title('Dataset con clusters solapados')\n","plt.xlabel('X1')\n","plt.ylabel('X2')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"in8RDacfOrtL"},"outputs":[],"source":["# =============================================================================\n","# EJERCICIO 3: Completar el código\n","# =============================================================================\n","\n","# Ajustar GMM con 2 componentes\n","gmm_soft = GaussianMixture(n_components=2, random_state=RANDOM_STATE)\n","gmm_soft.fit(X_ej3)\n","\n","# TODO: Obtener las probabilidades de pertenencia usando predict_proba()\n","probabilidades = None  # Completar\n","\n","# TODO: Obtener las etiquetas hard usando predict()\n","labels_hard = None  # Completar\n","\n","# TODO: Calcular la probabilidad máxima para cada punto\n","# (es decir, la probabilidad del cluster más probable)\n","prob_maxima = None  # Completar\n","\n","# TODO: Identificar puntos con alta incertidumbre (prob_maxima < 0.7)\n","mascara_inciertos = None  # Completar\n","n_inciertos = mascara_inciertos.sum()\n","\n","# Visualización\n","fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n","\n","# Hard clustering\n","ax = axes[0]\n","ax.scatter(X_ej3[:, 0], X_ej3[:, 1], c=labels_hard, cmap='coolwarm',\n","           edgecolors='w', s=40)\n","ax.set_title('Hard Clustering')\n","ax.set_xlabel('X1')\n","ax.set_ylabel('X2')\n","\n","# Probabilidad del cluster 0\n","ax = axes[1]\n","scatter = ax.scatter(X_ej3[:, 0], X_ej3[:, 1], c=probabilidades[:, 0],\n","                     cmap='coolwarm', edgecolors='w', s=40, vmin=0, vmax=1)\n","plt.colorbar(scatter, ax=ax, label='P(cluster 0)')\n","ax.set_title('Probabilidad de pertenencia al cluster 0')\n","ax.set_xlabel('X1')\n","ax.set_ylabel('X2')\n","\n","# Puntos inciertos resaltados\n","ax = axes[2]\n","ax.scatter(X_ej3[~mascara_inciertos, 0], X_ej3[~mascara_inciertos, 1],\n","           c='lightgray', edgecolors='w', s=40, label='Alta certeza')\n","ax.scatter(X_ej3[mascara_inciertos, 0], X_ej3[mascara_inciertos, 1],\n","           c='red', edgecolors='k', s=60, label='Alta incertidumbre')\n","ax.set_title(f'Puntos con alta incertidumbre\\n({n_inciertos} puntos con prob_max < 0.7)')\n","ax.set_xlabel('X1')\n","ax.set_ylabel('X2')\n","ax.legend()\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(f\"\\nEstadísticas de certeza:\")\n","print(f\"  Probabilidad máxima media: {prob_maxima.mean():.3f}\")\n","print(f\"  Puntos con alta incertidumbre: {n_inciertos} ({100*n_inciertos/len(X_ej3):.1f}%)\")"]},{"cell_type":"markdown","metadata":{"id":"z7DFY6hsOrtM"},"source":["### Preguntas de reflexión - Ejercicio 3\n","\n","1. ¿Dónde se concentran los puntos con alta incertidumbre? ¿Por qué?\n","2. ¿Cómo podrían utilizarse las probabilidades de pertenencia en una aplicación real?\n","3. ¿Qué ventaja tiene el soft clustering sobre el hard clustering para la toma de decisiones?"]},{"cell_type":"markdown","metadata":{"id":"HrQ50uOhOrtM"},"source":["---\n","\n","## Ejercicio 4: Clustering Espectral para Datos No Convexos\n","\n","### Objetivo\n","Aplicar clustering espectral a estructuras donde K-Means y GMM fallan, y analizar el efecto de los parámetros.\n","\n","### Contexto\n","Se proporciona un dataset con forma de medias lunas entrelazadas. Debe comparar diferentes algoritmos y configuraciones."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mzon1jyROrtM"},"outputs":[],"source":["# Generar dataset de medias lunas\n","X_ej4, y_ej4 = make_moons(n_samples=400, noise=0.08, random_state=RANDOM_STATE)\n","\n","plt.figure(figsize=(8, 6))\n","plt.scatter(X_ej4[:, 0], X_ej4[:, 1], c=y_ej4, cmap='viridis',\n","            edgecolors='w', s=40)\n","plt.title('Dataset de medias lunas (moons)')\n","plt.xlabel('X1')\n","plt.ylabel('X2')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g2sfRuD5OrtN"},"outputs":[],"source":["# =============================================================================\n","# EJERCICIO 4: Completar el código\n","# =============================================================================\n","\n","fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n","\n","# K-Means (baseline)\n","ax = axes[0]\n","kmeans = KMeans(n_clusters=2, random_state=RANDOM_STATE, n_init=10)\n","labels_km = kmeans.fit_predict(X_ej4)\n","ari_km = adjusted_rand_score(y_ej4, labels_km)\n","ax.scatter(X_ej4[:, 0], X_ej4[:, 1], c=labels_km, cmap='viridis', edgecolors='w', s=30)\n","ax.set_title(f'K-Means\\nARI: {ari_km:.3f}')\n","ax.set_xlabel('X1')\n","\n","# GMM\n","ax = axes[1]\n","gmm = GaussianMixture(n_components=2, random_state=RANDOM_STATE)\n","labels_gmm = gmm.fit_predict(X_ej4)\n","ari_gmm = adjusted_rand_score(y_ej4, labels_gmm)\n","ax.scatter(X_ej4[:, 0], X_ej4[:, 1], c=labels_gmm, cmap='viridis', edgecolors='w', s=30)\n","ax.set_title(f'GMM\\nARI: {ari_gmm:.3f}')\n","ax.set_xlabel('X1')\n","\n","# TODO: Clustering Espectral con affinity='rbf' y gamma=10\n","ax = axes[2]\n","spectral_rbf = None  # Completar: SpectralClustering con n_clusters=2, affinity='rbf', gamma=10\n","labels_rbf = None  # Completar: fit_predict\n","ari_rbf = adjusted_rand_score(y_ej4, labels_rbf)\n","ax.scatter(X_ej4[:, 0], X_ej4[:, 1], c=labels_rbf, cmap='viridis', edgecolors='w', s=30)\n","ax.set_title(f'Espectral (RBF, gamma=10)\\nARI: {ari_rbf:.3f}')\n","ax.set_xlabel('X1')\n","\n","# TODO: Clustering Espectral con affinity='nearest_neighbors' y n_neighbors=10\n","ax = axes[3]\n","spectral_knn = None  # Completar: SpectralClustering con affinity='nearest_neighbors', n_neighbors=10\n","labels_knn = None  # Completar: fit_predict\n","ari_knn = adjusted_rand_score(y_ej4, labels_knn)\n","ax.scatter(X_ej4[:, 0], X_ej4[:, 1], c=labels_knn, cmap='viridis', edgecolors='w', s=30)\n","ax.set_title(f'Espectral (k-NN, k=10)\\nARI: {ari_knn:.3f}')\n","ax.set_xlabel('X1')\n","\n","plt.suptitle('Comparación de algoritmos en datos no convexos', fontsize=13, fontweight='bold')\n","plt.tight_layout()\n","plt.show()\n","\n","print(f\"\\nResumen de ARI:\")\n","print(f\"  K-Means: {ari_km:.3f}\")\n","print(f\"  GMM: {ari_gmm:.3f}\")\n","print(f\"  Espectral (RBF): {ari_rbf:.3f}\")\n","print(f\"  Espectral (k-NN): {ari_knn:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"S5mHIpKVOrtN"},"source":["### Preguntas de reflexión - Ejercicio 4\n","\n","1. ¿Por qué K-Means y GMM no pueden separar correctamente las medias lunas?\n","2. ¿Qué diferencia hay entre usar affinity='rbf' vs 'nearest_neighbors'?\n","3. ¿Qué sucedería si gamma fuera muy pequeño (ej. 0.1) en el kernel RBF?"]},{"cell_type":"markdown","metadata":{"id":"1zKbufuiOrtN"},"source":["---\n","\n","## Ejercicio 5: Algoritmos que No Requieren K\n","\n","### Objetivo\n","Aplicar Mean-Shift y Affinity Propagation, que determinan automáticamente el número de clusters.\n","\n","### Contexto\n","Se proporciona un dataset donde el número de clusters es desconocido. Debe aplicar ambos algoritmos y analizar sus resultados."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wujy7PrkOrtO"},"outputs":[],"source":["# Generar dataset con número de clusters desconocido\n","np.random.seed(RANDOM_STATE)\n","\n","X_ej5, y_ej5 = make_blobs(n_samples=350, centers=5, cluster_std=0.7,\n","                          random_state=RANDOM_STATE)\n","\n","plt.figure(figsize=(8, 6))\n","plt.scatter(X_ej5[:, 0], X_ej5[:, 1], c='gray', edgecolors='w', s=40, alpha=0.7)\n","plt.title('Dataset con K desconocido')\n","plt.xlabel('X1')\n","plt.ylabel('X2')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTE_Vp0vOrtO"},"outputs":[],"source":["# =============================================================================\n","# EJERCICIO 5: Completar el código\n","# =============================================================================\n","\n","fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n","\n","# Ground truth\n","ax = axes[0]\n","ax.scatter(X_ej5[:, 0], X_ej5[:, 1], c=y_ej5, cmap='viridis', edgecolors='w', s=40)\n","ax.set_title(f'Ground Truth (K=5)')\n","ax.set_xlabel('X1')\n","ax.set_ylabel('X2')\n","\n","# Mean-Shift\n","ax = axes[1]\n","\n","# TODO: Estimar el bandwidth usando estimate_bandwidth con quantile=0.2\n","bandwidth = None  # Completar\n","\n","# TODO: Crear y ajustar MeanShift con el bandwidth estimado\n","ms = None  # Completar\n","labels_ms = None  # Completar\n","\n","k_ms = len(np.unique(labels_ms))\n","ari_ms = adjusted_rand_score(y_ej5, labels_ms)\n","\n","ax.scatter(X_ej5[:, 0], X_ej5[:, 1], c=labels_ms, cmap='viridis', edgecolors='w', s=40)\n","ax.scatter(ms.cluster_centers_[:, 0], ms.cluster_centers_[:, 1],\n","           c='red', marker='X', s=200, edgecolors='w', linewidths=2)\n","ax.set_title(f'Mean-Shift\\nK detectado: {k_ms}, ARI: {ari_ms:.3f}')\n","ax.set_xlabel('X1')\n","ax.set_ylabel('X2')\n","\n","# Affinity Propagation\n","ax = axes[2]\n","\n","# TODO: Crear y ajustar AffinityPropagation con damping=0.9 y preference=-50\n","ap = None  # Completar\n","labels_ap = None  # Completar\n","\n","k_ap = len(np.unique(labels_ap))\n","ari_ap = adjusted_rand_score(y_ej5, labels_ap)\n","\n","# Obtener ejemplares\n","ejemplares = ap.cluster_centers_indices_\n","\n","ax.scatter(X_ej5[:, 0], X_ej5[:, 1], c=labels_ap, cmap='viridis', edgecolors='w', s=40)\n","ax.scatter(X_ej5[ejemplares, 0], X_ej5[ejemplares, 1],\n","           c='red', marker='X', s=200, edgecolors='w', linewidths=2)\n","ax.set_title(f'Affinity Propagation\\nK detectado: {k_ap}, ARI: {ari_ap:.3f}')\n","ax.set_xlabel('X1')\n","ax.set_ylabel('X2')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(f\"\\nResultados:\")\n","print(f\"  K real: 5\")\n","print(f\"  Mean-Shift detectó: {k_ms} clusters (bandwidth={bandwidth:.2f})\")\n","print(f\"  Affinity Propagation detectó: {k_ap} clusters\")"]},{"cell_type":"markdown","metadata":{"id":"RgqeK9TnOrtP"},"source":["### Preguntas de reflexión - Ejercicio 5\n","\n","1. ¿Qué diferencia hay entre los centroides de Mean-Shift y los ejemplares de Affinity Propagation?\n","2. ¿Cómo afectaría cambiar el parámetro `preference` en Affinity Propagation?\n","3. ¿En qué escenarios sería preferible cada algoritmo?"]},{"cell_type":"markdown","metadata":{"id":"DIruuMCGOrtP"},"source":["---\n","\n","## Ejercicio 6: Caso Integrador - Segmentación de Clientes\n","\n","### Objetivo\n","Aplicar múltiples algoritmos del módulo a un problema de segmentación de clientes y seleccionar el mejor enfoque.\n","\n","### Contexto\n","Se dispone de datos de comportamiento de compra de clientes. Debe segmentarlos utilizando GMM, Clustering Espectral y BIRCH, comparando los resultados."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Di9jqlxSOrtP"},"outputs":[],"source":["# Generar datos de clientes simulados\n","np.random.seed(RANDOM_STATE)\n","\n","n_clientes = 500\n","\n","# Segmento 1: Clientes frecuentes de bajo gasto\n","seg1 = np.column_stack([\n","    np.random.normal(15, 3, 120),   # frecuencia mensual\n","    np.random.normal(25, 8, 120)    # gasto promedio\n","])\n","\n","# Segmento 2: Clientes ocasionales de alto gasto\n","seg2 = np.column_stack([\n","    np.random.normal(3, 1, 100),\n","    np.random.normal(150, 30, 100)\n","])\n","\n","# Segmento 3: Clientes premium (alta frecuencia, alto gasto)\n","seg3 = np.column_stack([\n","    np.random.normal(12, 2, 80),\n","    np.random.normal(120, 25, 80)\n","])\n","\n","# Segmento 4: Clientes inactivos\n","seg4 = np.column_stack([\n","    np.random.normal(1, 0.5, 200),\n","    np.random.normal(20, 10, 200)\n","])\n","\n","X_clientes = np.vstack([seg1, seg2, seg3, seg4])\n","X_clientes = np.clip(X_clientes, 0, None)  # No valores negativos\n","y_clientes = np.array([0]*120 + [1]*100 + [2]*80 + [3]*200)\n","\n","# Estandarizar\n","scaler = StandardScaler()\n","X_clientes_scaled = scaler.fit_transform(X_clientes)\n","\n","# Visualizar\n","plt.figure(figsize=(10, 6))\n","scatter = plt.scatter(X_clientes[:, 0], X_clientes[:, 1], c=y_clientes,\n","                      cmap='viridis', edgecolors='w', s=40, alpha=0.7)\n","plt.xlabel('Frecuencia mensual de compra')\n","plt.ylabel('Gasto promedio por compra')\n","plt.title('Datos de clientes (Ground Truth)')\n","plt.colorbar(scatter, label='Segmento')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJIAqoAPOrtP"},"outputs":[],"source":["# =============================================================================\n","# EJERCICIO 6: Completar el código\n","# =============================================================================\n","\n","# Primero, usar BIC para determinar K óptimo con GMM\n","bics_clientes = []\n","for k in range(2, 8):\n","    gmm_temp = GaussianMixture(n_components=k, random_state=RANDOM_STATE)\n","    gmm_temp.fit(X_clientes_scaled)\n","    bics_clientes.append(gmm_temp.bic(X_clientes_scaled))\n","\n","k_optimo = np.argmin(bics_clientes) + 2\n","print(f\"K óptimo según BIC: {k_optimo}\")\n","\n","# Comparar algoritmos con K=4\n","resultados_clientes = []\n","\n","# TODO: GMM con covariance_type='full'\n","gmm_clientes = None  # Completar\n","labels_gmm_c = None  # Completar\n","ari_gmm_c = adjusted_rand_score(y_clientes, labels_gmm_c)\n","sil_gmm_c = silhouette_score(X_clientes_scaled, labels_gmm_c)\n","resultados_clientes.append(('GMM', ari_gmm_c, sil_gmm_c, labels_gmm_c))\n","\n","# TODO: Clustering Espectral con affinity='rbf'\n","spec_clientes = None  # Completar\n","labels_spec_c = None  # Completar\n","ari_spec_c = adjusted_rand_score(y_clientes, labels_spec_c)\n","sil_spec_c = silhouette_score(X_clientes_scaled, labels_spec_c)\n","resultados_clientes.append(('Espectral', ari_spec_c, sil_spec_c, labels_spec_c))\n","\n","# TODO: BIRCH con n_clusters=4 y threshold=0.5\n","birch_clientes = None  # Completar\n","labels_birch_c = None  # Completar\n","ari_birch_c = adjusted_rand_score(y_clientes, labels_birch_c)\n","sil_birch_c = silhouette_score(X_clientes_scaled, labels_birch_c)\n","resultados_clientes.append(('BIRCH', ari_birch_c, sil_birch_c, labels_birch_c))\n","\n","# Visualización\n","fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n","\n","# Ground truth\n","ax = axes[0]\n","ax.scatter(X_clientes[:, 0], X_clientes[:, 1], c=y_clientes,\n","           cmap='viridis', edgecolors='w', s=30, alpha=0.7)\n","ax.set_title('Ground Truth')\n","ax.set_xlabel('Frecuencia')\n","ax.set_ylabel('Gasto promedio')\n","\n","# Resultados de cada algoritmo\n","for i, (nombre, ari, sil, labels) in enumerate(resultados_clientes):\n","    ax = axes[i+1]\n","    ax.scatter(X_clientes[:, 0], X_clientes[:, 1], c=labels,\n","               cmap='viridis', edgecolors='w', s=30, alpha=0.7)\n","    ax.set_title(f'{nombre}\\nARI: {ari:.3f}, Silueta: {sil:.3f}')\n","    ax.set_xlabel('Frecuencia')\n","    ax.set_ylabel('Gasto promedio')\n","\n","plt.suptitle('Comparación de algoritmos en segmentación de clientes',\n","             fontsize=13, fontweight='bold')\n","plt.tight_layout()\n","plt.show()\n","\n","# Tabla comparativa\n","print(\"\\nComparación de algoritmos:\")\n","print(\"-\" * 45)\n","print(f\"{'Algoritmo':<15} {'ARI':<10} {'Silueta':<10}\")\n","print(\"-\" * 45)\n","for nombre, ari, sil, _ in resultados_clientes:\n","    print(f\"{nombre:<15} {ari:<10.4f} {sil:<10.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"dTQbsXLtOrtQ"},"source":["### Preguntas de reflexión - Ejercicio 6\n","\n","1. ¿Qué algoritmo obtuvo mejores resultados? ¿Por qué cree que fue así?\n","2. ¿Qué ventajas tendría GMM sobre BIRCH para este caso de segmentación?\n","3. Si el dataset tuviera millones de clientes, ¿qué algoritmo recomendaría?"]},{"cell_type":"markdown","source":["---\n","# EOF (End Of File)"],"metadata":{"id":"jQJpadlaWBAq"}}]}