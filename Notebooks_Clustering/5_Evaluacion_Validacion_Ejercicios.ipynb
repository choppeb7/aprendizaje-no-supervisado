{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["JveBRwnwf-vO"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Evaluación y Validación de Clusters - Ejercicios"],"metadata":{"id":"TvBM341WgKJ8"}},{"cell_type":"markdown","metadata":{"id":"IeDAK8S6f-uN"},"source":["\n","\n","---\n","Este notebook contiene ejercicios prácticos para consolidar los conceptos del Módulo Evaluación y validación de Clusters\n"]},{"cell_type":"markdown","metadata":{"id":"A7n8GTnOf-us"},"source":["## Configuración Inicial"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J7fljhU2f-ut"},"outputs":[],"source":["# Importar bibliotecas necesarias\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Scikit-learn: clustering\n","from sklearn.cluster import KMeans, AgglomerativeClustering\n","from sklearn.mixture import GaussianMixture\n","\n","# Scikit-learn: métricas internas\n","from sklearn.metrics import (\n","    silhouette_score, silhouette_samples,\n","    calinski_harabasz_score, davies_bouldin_score\n",")\n","\n","# Scikit-learn: métricas externas\n","from sklearn.metrics import (\n","    adjusted_rand_score, normalized_mutual_info_score,\n","    homogeneity_score, completeness_score, v_measure_score,\n","    fowlkes_mallows_score\n",")\n","\n","# Scikit-learn: datasets y preprocesamiento\n","from sklearn.datasets import make_blobs, make_moons, load_iris\n","from sklearn.preprocessing import StandardScaler\n","\n","# Configuración\n","plt.style.use('seaborn-v0_8-whitegrid')\n","plt.rcParams['figure.figsize'] = (12, 5)\n","plt.rcParams['font.size'] = 11\n","\n","RANDOM_STATE = 42\n","np.random.seed(RANDOM_STATE)\n","\n","print(\"Entorno configurado correctamente.\")"]},{"cell_type":"markdown","metadata":{"id":"uUWSIUrkf-u0"},"source":["---\n","\n","## Ejercicio 1: Cálculo de Métricas Internas\n","\n","### Objetivo\n","Calcular e interpretar las tres métricas internas principales: Silueta, Calinski-Harabasz y Davies-Bouldin.\n","\n","### Contexto\n","Se proporcionan dos datasets con diferente calidad de separación entre clusters. Debe calcular las métricas y compararlas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YsJ7cRQPf-u1"},"outputs":[],"source":["# Generar dos datasets con diferente separación\n","np.random.seed(RANDOM_STATE)\n","\n","# Dataset A: clusters bien separados\n","X_A, y_A = make_blobs(n_samples=300, centers=3, cluster_std=0.6, random_state=RANDOM_STATE)\n","\n","# Dataset B: clusters más solapados\n","X_B, y_B = make_blobs(n_samples=300, centers=3, cluster_std=3.5, random_state=RANDOM_STATE)\n","\n","# Visualizar\n","fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n","\n","axes[0].scatter(X_A[:, 0], X_A[:, 1], c=y_A, cmap='viridis', edgecolors='w', s=40)\n","axes[0].set_title('Dataset A: Clusters bien separados')\n","axes[0].set_xlabel('X1')\n","axes[0].set_ylabel('X2')\n","\n","axes[1].scatter(X_B[:, 0], X_B[:, 1], c=y_B, cmap='viridis', edgecolors='w', s=40)\n","axes[1].set_title('Dataset B: Clusters solapados')\n","axes[1].set_xlabel('X1')\n","axes[1].set_ylabel('X2')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X9-Wykc3f-u2"},"outputs":[],"source":["# =============================================================================\n","# EJERCICIO 1: Completar el código\n","# =============================================================================\n","\n","# Aplicar K-Means a ambos datasets\n","kmeans_A = KMeans(n_clusters=3, random_state=RANDOM_STATE, n_init=10)\n","labels_A = kmeans_A.fit_predict(X_A)\n","\n","kmeans_B = KMeans(n_clusters=3, random_state=RANDOM_STATE, n_init=10)\n","labels_B = kmeans_B.fit_predict(X_B)\n","\n","# TODO: Calcular el coeficiente de silueta para ambos datasets\n","silueta_A = None  # Completar\n","silueta_B = None  # Completar\n","\n","# TODO: Calcular el índice de Calinski-Harabasz para ambos datasets\n","ch_A = None  # Completar\n","ch_B = None  # Completar\n","\n","# TODO: Calcular el índice de Davies-Bouldin para ambos datasets\n","db_A = None  # Completar\n","db_B = None  # Completar\n","\n","# Mostrar resultados\n","print(\"Comparación de métricas internas:\")\n","print(\"=\" * 55)\n","print(f\"{'Métrica':<20} {'Dataset A':<15} {'Dataset B':<15}\")\n","print(\"-\" * 55)\n","print(f\"{'Silueta':<20} {silueta_A:<15.4f} {silueta_B:<15.4f}\")\n","print(f\"{'Calinski-Harabasz':<20} {ch_A:<15.2f} {ch_B:<15.2f}\")\n","print(f\"{'Davies-Bouldin':<20} {db_A:<15.4f} {db_B:<15.4f}\")\n","print(\"=\" * 55)"]},{"cell_type":"markdown","metadata":{"id":"JajIZ52ef-u3"},"source":["### Preguntas de reflexión - Ejercicio 1\n","\n","1. ¿Qué dataset tiene mejor calidad de clustering según cada métrica? ¿Coinciden todas?\n","2. ¿Por qué Davies-Bouldin es menor para clusters bien separados?\n","3. Si solo pudiera usar una métrica interna, ¿cuál elegiría y por qué?"]},{"cell_type":"markdown","metadata":{"id":"ZK804ttBf-vB"},"source":["---\n","\n","## Ejercicio 2: Métricas Externas con Ground Truth\n","\n","### Objetivo\n","Calcular métricas externas comparando las predicciones de clustering con etiquetas verdaderas.\n","\n","### Contexto\n","Se aplican diferentes algoritmos de clustering al mismo dataset y se comparan usando métricas externas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Y7k0BDPf-vC"},"outputs":[],"source":["# Generar dataset con ground truth conocido\n","np.random.seed(RANDOM_STATE)\n","X_ej2, y_true = make_blobs(n_samples=400, centers=4, cluster_std=2.5, random_state=RANDOM_STATE)\n","\n","# Visualizar ground truth\n","plt.figure(figsize=(8, 6))\n","plt.scatter(X_ej2[:, 0], X_ej2[:, 1], c=y_true, cmap='viridis', edgecolors='w', s=40)\n","plt.title('Dataset con ground truth (K=4)')\n","plt.xlabel('X1')\n","plt.ylabel('X2')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCEjq-g4f-vI"},"outputs":[],"source":["# =============================================================================\n","# EJERCICIO 2: Completar el código\n","# =============================================================================\n","\n","# Aplicar tres algoritmos de clustering\n","kmeans = KMeans(n_clusters=4, random_state=RANDOM_STATE, n_init=10)\n","labels_kmeans = kmeans.fit_predict(X_ej2)\n","\n","hier = AgglomerativeClustering(n_clusters=4, linkage='ward')\n","labels_hier = hier.fit_predict(X_ej2)\n","\n","gmm = GaussianMixture(n_components=4, random_state=RANDOM_STATE)\n","labels_gmm = gmm.fit_predict(X_ej2)\n","\n","# Almacenar resultados\n","resultados = []\n","\n","for nombre, labels in [('K-Means', labels_kmeans), ('Hierarchical', labels_hier), ('GMM', labels_gmm)]:\n","    # TODO: Calcular Adjusted Rand Index\n","    ari = None  # Completar\n","\n","    # TODO: Calcular Normalized Mutual Information\n","    nmi = None  # Completar\n","\n","    # TODO: Calcular V-measure\n","    v_m = None  # Completar\n","\n","    # TODO: Calcular Fowlkes-Mallows Index\n","    fmi = None  # Completar\n","\n","    resultados.append({\n","        'Algoritmo': nombre,\n","        'ARI': ari,\n","        'NMI': nmi,\n","        'V-measure': v_m,\n","        'FMI': fmi\n","    })\n","\n","# Mostrar tabla de resultados\n","df_resultados = pd.DataFrame(resultados)\n","print(\"\\nComparación de algoritmos usando métricas externas:\")\n","print(\"=\" * 65)\n","print(df_resultados.to_string(index=False))"]},{"cell_type":"markdown","metadata":{"id":"ABAK3vndf-vK"},"source":["### Preguntas de reflexión - Ejercicio 2\n","\n","1. ¿Qué algoritmo obtiene los mejores resultados según las métricas externas?\n","2. ¿Por qué ARI puede ser negativo mientras que NMI siempre es positivo?\n","3. ¿En qué situaciones reales tendríamos acceso a ground truth para usar estas métricas?"]},{"cell_type":"markdown","metadata":{"id":"qWOIlDzFf-vL"},"source":["---\n","\n","## Ejercicio 3: Selección de K con Métricas Internas\n","\n","### Objetivo\n","Utilizar métricas internas para determinar el número óptimo de clusters.\n","\n","### Contexto\n","Se proporciona un dataset sin revelar el número real de clusters. Debe usar las métricas para determinarlo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"13xR-PDef-vM"},"outputs":[],"source":["# Generar dataset con número de clusters oculto\n","np.random.seed(RANDOM_STATE)\n","X_ej3, y_ej3 = make_blobs(n_samples=500, centers=5, cluster_std=2.0, random_state=RANDOM_STATE)\n","\n","# Visualizar sin etiquetas\n","plt.figure(figsize=(8, 6))\n","plt.scatter(X_ej3[:, 0], X_ej3[:, 1], c='gray', edgecolors='w', s=40, alpha=0.7)\n","plt.title('Dataset para selección de K')\n","plt.xlabel('X1')\n","plt.ylabel('X2')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jroKOnQpf-vN"},"outputs":[],"source":["# =============================================================================\n","# EJERCICIO 3: Completar el código\n","# =============================================================================\n","\n","# Rango de K a evaluar\n","rango_k = range(2, 10)\n","\n","# Listas para almacenar métricas\n","siluetas = []\n","ch_scores = []\n","db_scores = []\n","\n","for k in rango_k:\n","    kmeans = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)\n","    labels = kmeans.fit_predict(X_ej3)\n","\n","    # TODO: Calcular y almacenar silueta\n","    sil = None  # Completar\n","    siluetas.append(sil)\n","\n","    # TODO: Calcular y almacenar Calinski-Harabasz\n","    ch = None  # Completar\n","    ch_scores.append(ch)\n","\n","    # TODO: Calcular y almacenar Davies-Bouldin\n","    db = None  # Completar\n","    db_scores.append(db)\n","\n","# TODO: Encontrar K óptimo según cada métrica\n","k_opt_sil = None  # Completar: K que maximiza silueta\n","k_opt_ch = None   # Completar: K que maximiza CH\n","k_opt_db = None   # Completar: K que minimiza DB\n","\n","# Visualización\n","fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n","\n","# Silueta\n","ax = axes[0]\n","ax.plot(list(rango_k), siluetas, 'b-o', linewidth=2, markersize=8)\n","ax.axvline(x=k_opt_sil, color='red', linestyle='--', label=f'K óptimo = {k_opt_sil}')\n","ax.set_xlabel('K')\n","ax.set_ylabel('Silueta')\n","ax.set_title('Coeficiente de Silueta (Mayor = Mejor)')\n","ax.legend()\n","ax.grid(True, alpha=0.3)\n","\n","# Calinski-Harabasz\n","ax = axes[1]\n","ax.plot(list(rango_k), ch_scores, 'g-o', linewidth=2, markersize=8)\n","ax.axvline(x=k_opt_ch, color='red', linestyle='--', label=f'K óptimo = {k_opt_ch}')\n","ax.set_xlabel('K')\n","ax.set_ylabel('Calinski-Harabasz')\n","ax.set_title('Índice de Calinski-Harabasz (Mayor = Mejor)')\n","ax.legend()\n","ax.grid(True, alpha=0.3)\n","\n","# Davies-Bouldin\n","ax = axes[2]\n","ax.plot(list(rango_k), db_scores, 'r-o', linewidth=2, markersize=8)\n","ax.axvline(x=k_opt_db, color='green', linestyle='--', label=f'K óptimo = {k_opt_db}')\n","ax.set_xlabel('K')\n","ax.set_ylabel('Davies-Bouldin')\n","ax.set_title('Índice de Davies-Bouldin (Menor = Mejor)')\n","ax.legend()\n","ax.grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(f\"\\nK óptimo según Silueta: {k_opt_sil}\")\n","print(f\"K óptimo según Calinski-Harabasz: {k_opt_ch}\")\n","print(f\"K óptimo según Davies-Bouldin: {k_opt_db}\")"]},{"cell_type":"markdown","metadata":{"id":"fRlv4DgZf-vO"},"source":["### Preguntas de reflexión - Ejercicio 3\n","\n","1. ¿Coinciden las tres métricas en el K óptimo? Si no coinciden, ¿cuál priorizaría?\n","2. ¿Por qué Calinski-Harabasz tiende a decrecer monótonamente después del óptimo?\n","3. ¿Qué haría si las métricas sugieren valores de K muy diferentes?"]},{"cell_type":"markdown","metadata":{"id":"JveBRwnwf-vO"},"source":["---\n","\n","## Ejercicio 4: Análisis de Silueta Visual\n","\n","### Objetivo\n","Crear e interpretar un gráfico de análisis de silueta por cluster para diagnóstico detallado.\n","\n","### Contexto\n","Se proporciona un dataset con clusters de diferente calidad. El análisis visual permite identificar clusters problemáticos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"maYRg2eKf-vP"},"outputs":[],"source":["# Generar dataset con clusters de diferente calidad\n","np.random.seed(RANDOM_STATE)\n","\n","# Cluster 0: compacto\n","c0 = np.random.randn(100, 2) * 0.5 + [0, 0]\n","# Cluster 1: disperso\n","c1 = np.random.randn(100, 2) * 2.0 + [6, 0]\n","# Cluster 2: compacto\n","c2 = np.random.randn(100, 2) * 0.5 + [3, 5]\n","\n","X_ej4 = np.vstack([c0, c1, c2])\n","y_ej4 = np.array([0]*100 + [1]*100 + [2]*100)\n","\n","# Aplicar K-Means\n","kmeans_ej4 = KMeans(n_clusters=3, random_state=RANDOM_STATE, n_init=10)\n","labels_ej4 = kmeans_ej4.fit_predict(X_ej4)\n","\n","print(\"Dataset generado con 3 clusters de diferente dispersión.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcagI19If-vQ"},"outputs":[],"source":["# =============================================================================\n","# EJERCICIO 4: Completar el código\n","# =============================================================================\n","\n","# TODO: Calcular silueta global\n","silueta_global = None  # Completar\n","\n","# TODO: Calcular siluetas individuales (por punto)\n","siluetas_individuales = None  # Completar: usar silhouette_samples\n","\n","# Crear visualización\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n","\n","# Gráfico de silueta por cluster\n","y_lower = 10\n","n_clusters = 3\n","colors = cm.viridis(np.linspace(0, 1, n_clusters))\n","\n","for i in range(n_clusters):\n","    # TODO: Obtener siluetas del cluster i\n","    cluster_silhouettes = None  # Completar: siluetas_individuales[labels_ej4 == i]\n","    cluster_silhouettes.sort()\n","\n","    size_cluster = len(cluster_silhouettes)\n","    y_upper = y_lower + size_cluster\n","\n","    ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouettes,\n","                      facecolor=colors[i], edgecolor=colors[i], alpha=0.7)\n","    ax1.text(-0.05, y_lower + 0.5 * size_cluster, str(i), fontsize=12)\n","\n","    # TODO: Calcular e imprimir silueta media del cluster\n","    media_cluster = None  # Completar\n","    print(f\"Cluster {i}: silueta media = {media_cluster:.4f}, tamaño = {size_cluster}\")\n","\n","    y_lower = y_upper + 10\n","\n","# Línea de silueta promedio\n","ax1.axvline(x=silueta_global, color='red', linestyle='--',\n","            label=f'Silueta media: {silueta_global:.3f}')\n","ax1.axvline(x=0, color='gray', linestyle='-', alpha=0.5)\n","ax1.set_xlabel('Coeficiente de silueta')\n","ax1.set_ylabel('Cluster')\n","ax1.set_title('Análisis de silueta por cluster')\n","ax1.set_xlim([-0.2, 1])\n","ax1.legend()\n","\n","# Gráfico de dispersión\n","ax2.scatter(X_ej4[:, 0], X_ej4[:, 1], c=labels_ej4, cmap='viridis', edgecolors='w', s=40)\n","ax2.scatter(kmeans_ej4.cluster_centers_[:, 0], kmeans_ej4.cluster_centers_[:, 1],\n","            c='red', marker='X', s=200, edgecolors='w')\n","ax2.set_xlabel('X1')\n","ax2.set_ylabel('X2')\n","ax2.set_title('Asignación de clusters')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"l6Gie-Drf-vR"},"source":["### Preguntas de reflexión - Ejercicio 4\n","\n","1. ¿Qué cluster tiene la peor calidad según el análisis de silueta? ¿Por qué?\n","2. ¿Qué indica cuando un cluster tiene muchos puntos con silueta negativa?\n","3. ¿Cómo usaría este análisis para mejorar el clustering?"]},{"cell_type":"markdown","metadata":{"id":"ilbVlA9gf-vR"},"source":["---\n","\n","## Ejercicio 5: Homogeneidad vs Completitud\n","\n","### Objetivo\n","Comprender la diferencia entre homogeneidad y completitud mediante casos extremos.\n","\n","### Contexto\n","Se crean diferentes particiones artificiales para ilustrar cómo estas métricas capturan aspectos diferentes de la calidad."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFDY-zWRf-vR"},"outputs":[],"source":["# Dataset simple con 3 clases\n","np.random.seed(RANDOM_STATE)\n","X_ej5, y_true_ej5 = make_blobs(n_samples=150, centers=3, cluster_std=0.5, random_state=RANDOM_STATE)\n","\n","print(f\"Dataset con {len(y_true_ej5)} puntos y 3 clases verdaderas.\")\n","print(f\"Distribución de clases: {np.bincount(y_true_ej5)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5dPENVFQf-vS"},"outputs":[],"source":["# =============================================================================\n","# EJERCICIO 5: Completar el código\n","# =============================================================================\n","\n","# Caso 1: Clustering perfecto (3 clusters que coinciden con las clases)\n","labels_perfecto = y_true_ej5.copy()\n","\n","# Caso 2: Sobre-segmentación (cada punto es su propio cluster)\n","labels_sobre = np.arange(len(y_true_ej5))\n","\n","# Caso 3: Sub-segmentación (todos en un solo cluster)\n","labels_sub = np.zeros(len(y_true_ej5), dtype=int)\n","\n","# Caso 4: Clustering con K-Means (3 clusters)\n","kmeans_ej5 = KMeans(n_clusters=3, random_state=RANDOM_STATE, n_init=10)\n","labels_kmeans = kmeans_ej5.fit_predict(X_ej5)\n","\n","# Calcular métricas para cada caso\n","casos = [\n","    ('Perfecto', labels_perfecto),\n","    ('Sobre-segmentación', labels_sobre),\n","    ('Sub-segmentación', labels_sub),\n","    ('K-Means', labels_kmeans)\n","]\n","\n","print(\"\\nComparación de Homogeneidad y Completitud:\")\n","print(\"=\" * 70)\n","print(f\"{'Caso':<20} {'Homogeneidad':<15} {'Completitud':<15} {'V-measure':<15}\")\n","print(\"-\" * 70)\n","\n","for nombre, labels in casos:\n","    # TODO: Calcular homogeneidad\n","    h = None  # Completar\n","\n","    # TODO: Calcular completitud\n","    c = None  # Completar\n","\n","    # TODO: Calcular V-measure\n","    v = None  # Completar\n","\n","    print(f\"{nombre:<20} {h:<15.4f} {c:<15.4f} {v:<15.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"QRp374qXf-vT"},"source":["### Preguntas de reflexión - Ejercicio 5\n","\n","1. ¿Por qué la sobre-segmentación tiene homogeneidad perfecta pero completitud mínima?\n","2. ¿Por qué la sub-segmentación tiene completitud perfecta pero homogeneidad mínima?\n","3. ¿En qué aplicaciones sería más importante priorizar homogeneidad sobre completitud?"]},{"cell_type":"markdown","metadata":{"id":"uwZrdsNDf-vT"},"source":["---\n","\n","## Ejercicio 6: Caso Integrador - Evaluación Completa\n","\n","### Objetivo\n","Realizar una evaluación completa de clustering combinando métricas internas, externas y análisis visual.\n","\n","### Contexto\n","Se utiliza el dataset Iris para comparar múltiples algoritmos de clustering de forma integral."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dRYLpDGrf-vc"},"outputs":[],"source":["# Cargar dataset Iris\n","iris = load_iris()\n","X_iris = iris.data\n","y_iris = iris.target\n","\n","# Estandarizar\n","scaler = StandardScaler()\n","X_iris_scaled = scaler.fit_transform(X_iris)\n","\n","print(f\"Dataset Iris:\")\n","print(f\"  Muestras: {X_iris.shape[0]}\")\n","print(f\"  Características: {X_iris.shape[1]}\")\n","print(f\"  Clases: {len(np.unique(y_iris))}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKfiFt8mf-vc"},"outputs":[],"source":["# =============================================================================\n","# EJERCICIO 6: Completar el código\n","# =============================================================================\n","\n","# Definir algoritmos\n","algoritmos = {\n","    'K-Means': KMeans(n_clusters=3, random_state=RANDOM_STATE, n_init=10),\n","    'Hierarchical': AgglomerativeClustering(n_clusters=3, linkage='ward'),\n","    'GMM': GaussianMixture(n_components=3, random_state=RANDOM_STATE)\n","}\n","\n","# Almacenar resultados\n","resultados_completos = []\n","\n","for nombre, modelo in algoritmos.items():\n","    labels = modelo.fit_predict(X_iris_scaled)\n","\n","    # TODO: Calcular métricas internas\n","    sil = None  # Completar\n","    ch = None   # Completar\n","    db = None   # Completar\n","\n","    # TODO: Calcular métricas externas\n","    ari = None  # Completar\n","    nmi = None  # Completar\n","\n","    resultados_completos.append({\n","        'Algoritmo': nombre,\n","        'Silueta': sil,\n","        'CH': ch,\n","        'DB': db,\n","        'ARI': ari,\n","        'NMI': nmi,\n","        'labels': labels\n","    })\n","\n","# Crear DataFrame sin la columna de labels\n","df_final = pd.DataFrame([{k: v for k, v in r.items() if k != 'labels'}\n","                         for r in resultados_completos])\n","\n","print(\"\\nEvaluación completa en dataset Iris:\")\n","print(\"=\" * 75)\n","print(df_final.to_string(index=False))\n","print(\"\\nNota: Silueta, CH y ARI/NMI son mejores cuando son mayores; DB es mejor cuando es menor.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ZRpAnE7f-ve"},"outputs":[],"source":["# Visualización comparativa (usando solo las 2 primeras características)\n","fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n","\n","# Ground truth\n","ax = axes[0]\n","ax.scatter(X_iris[:, 0], X_iris[:, 1], c=y_iris, cmap='viridis', edgecolors='w', s=50)\n","ax.set_title('Ground Truth')\n","ax.set_xlabel(iris.feature_names[0])\n","ax.set_ylabel(iris.feature_names[1])\n","\n","# Resultados de cada algoritmo\n","for i, resultado in enumerate(resultados_completos):\n","    ax = axes[i + 1]\n","    ax.scatter(X_iris[:, 0], X_iris[:, 1], c=resultado['labels'],\n","               cmap='viridis', edgecolors='w', s=50)\n","    ax.set_title(f\"{resultado['Algoritmo']}\\nARI: {resultado['ARI']:.3f}\")\n","    ax.set_xlabel(iris.feature_names[0])\n","    ax.set_ylabel(iris.feature_names[1])\n","\n","plt.suptitle('Comparación de algoritmos en dataset Iris', fontsize=14, fontweight='bold')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"HSi8omHQf-ve"},"source":["### Preguntas de reflexión - Ejercicio 6\n","\n","1. ¿Qué algoritmo obtiene los mejores resultados globalmente? ¿Coinciden las métricas internas y externas?\n","2. Si no tuviera acceso al ground truth, ¿cómo decidiría qué algoritmo es mejor?\n","3. ¿Por qué es importante usar múltiples métricas en lugar de una sola?"]},{"cell_type":"markdown","source":["---\n","\n","# EOF (End Of File)"],"metadata":{"id":"tfPZnArxmywb"}}]}